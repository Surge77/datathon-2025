{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68efa021",
   "metadata": {},
   "source": [
    "## 1) Imports & paths\n",
    "##### üí° Concept\n",
    "Before manipulating data, we must set up the environment ‚Äî define where data lives and where cleaned outputs will go. Think of this like laying out your lab tools before starting an experiment. Without consistent paths, reproducibility collapses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1ab50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re, json\n",
    "from pathlib import Path\n",
    "RNG = 42\n",
    "\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "DATA_RAW = ROOT / \"data\" / \"raw\"\n",
    "DATA_PROC = ROOT / \"data\" / \"processed\"\n",
    "REPORTS = ROOT / \"reports\"\n",
    "FIGS = ROOT / \"outputs\" / \"figures\"\n",
    "\n",
    "DATA_PROC.mkdir(parents=True, exist_ok=True)\n",
    "REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "FIGS.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce652e",
   "metadata": {},
   "source": [
    "## 2) Load raw datasets\n",
    "\n",
    "##### üí° Concept\n",
    "At its core, ‚Äúloading‚Äù isn‚Äôt just reading CSVs ‚Äî it‚Äôs about validating the data contract.\n",
    "Each dataset has a schema (columns, types, units). Before merging, you must check whether those schemas align or conflict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(DATA_RAW / \"dataset1_data_science_job.csv\")\n",
    "df2 = pd.read_csv(DATA_RAW / \"dataset2_all_job_post.csv\")\n",
    "df3 = pd.read_csv(DATA_RAW / \"dataset3_ai_job_dataset.csv\")\n",
    "\n",
    "for name, df in {\"df1\": df1, \"df2\": df2, \"df3\": df3}.items():\n",
    "    print(name, df.shape); display(df.head(2)); display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b99ea",
   "metadata": {},
   "source": [
    "## 3) Profiling snapshot (lightweight)\n",
    "\n",
    "##### üí° Concept\n",
    "Profiling is the diagnostic stage of cleaning ‚Äî like running blood tests before prescribing medicine.\n",
    "It tells you what‚Äôs wrong: missing values, strange datatypes, duplicates, etc.\n",
    "Without this, cleaning becomes random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e2158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile(df: pd.DataFrame, name: str) -> dict:\n",
    "    \"\"\"Return basic profile stats for df. \n",
    "    Time: O(n * c). Space: O(c).\"\"\"\n",
    "    return {\n",
    "        \"rows\": len(df),\n",
    "        \"cols\": df.shape[1],\n",
    "        \"na_counts\": df.isna().sum().to_dict(),\n",
    "        \"dup_rows\": int(df.duplicated().sum()),\n",
    "        \"numeric_cols\": df.select_dtypes(include=\"number\").columns.tolist(),\n",
    "        \"object_cols\": df.select_dtypes(include=\"object\").columns.tolist(),\n",
    "    }\n",
    "\n",
    "profiles = {k: profile(v, k) for k, v in {\"df1\": df1, \"df2\": df2, \"df3\": df3}.items()}\n",
    "print(json.dumps(profiles, indent=2)[:2000], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0900ec10",
   "metadata": {},
   "source": [
    "## 4Ô∏è) Schema Harmonization\n",
    "\n",
    "##### üí° Concept\n",
    "Datasets from different sources often call the same thing by different names ‚Äî e.g., job_title vs title.\n",
    "Before merging, we need a shared vocabulary.\n",
    "This is the lingua franca of your data ‚Äî making sure everyone (and every dataset) ‚Äúspeaks the same language‚Äù."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52015bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLMAP = {\n",
    "    \"title\": \"job_title\",\n",
    "    \"jobTitle\": \"job_title\",\n",
    "    \"category\": \"job_category\",          # NEW\n",
    "    \"skills\": \"required_skills\",\n",
    "    \"job_skill_set\": \"required_skills\",  # NEW\n",
    "    \"experience\": \"experience_level\",\n",
    "    \"exp_level\": \"experience_level\",\n",
    "    \"salary_in_usd\": \"salary_usd\",       # NEW\n",
    "    \"salary_usd\": \"salary_usd\",\n",
    "    \"salaryLocal\": \"salary_local\",       # just in case\n",
    "    \"salary\": \"salary\",\n",
    "    \"location\": \"company_location\",\n",
    "    \"posted_at\": \"posting_date\",\n",
    "}\n",
    "\n",
    "DATE_COLS = [\"posting_date\", \"application_deadline\"]\n",
    "NUM_COLS  = [\"salary_usd\", \"salary\", \"salary_local\",\n",
    "             \"remote_ratio\", \"years_experience\",\n",
    "             \"benefits_score\", \"job_description_length\"]\n",
    "\n",
    "def harmonize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Standardize schema + dtypes. Time: O(n+c), Space: ~O(1) extra.\"\"\"\n",
    "    out = df.rename(columns={k:v for k,v in COLMAP.items() if k in df.columns}).copy()\n",
    "    for d in DATE_COLS:\n",
    "        if d in out.columns:\n",
    "            out[d] = pd.to_datetime(out[d], errors=\"coerce\")\n",
    "    for n in NUM_COLS:\n",
    "        if n in out.columns:\n",
    "            out[n] = pd.to_numeric(out[n], errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "df1h, df2h, df3h = map(harmonize, (df1, df2, df3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749790df",
   "metadata": {},
   "source": [
    "## 5Ô∏è) Missing Values & ‚ÄúUnknown‚Äù Categories\n",
    "\n",
    "##### üí° Concept\n",
    "Missing data is information ‚Äî it tells you where the system failed to observe.  \n",
    "We never randomly ‚Äúfill‚Äù it; we reason about why it‚Äôs missing.  \n",
    "Duplicates distort truth ‚Äî one job posted twice looks like double demand.  \n",
    "Here, imputation = an informed guess.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "241e7d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(df):\n",
    "    out = df.copy()\n",
    "    for c in out.select_dtypes(\"object\"):\n",
    "        out[c] = out[c].fillna(\"Unknown\")\n",
    "    for c in out.select_dtypes(\"number\"):\n",
    "        out[c] = out[c].fillna(out[c].median())\n",
    "    return out.drop_duplicates()\n",
    "\n",
    "df1c, df2c, df3c = map(fill_missing, (df1h, df2h, df3h))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
