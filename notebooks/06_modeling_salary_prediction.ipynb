{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_modeling_salary_prediction.ipynb — Salary Prediction Engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment ready.\n",
      "Data path -> C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\tables\\master_jobs_ready.csv\n",
      "Figures   -> C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\figures\n",
      "Models    -> C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\models\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 1) Setup & imports\n",
    "# ==========================\n",
    "import os, json, math, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "# Optional: third-party encoders & xgboost and shap\n",
    "try:\n",
    "    import category_encoders as ce\n",
    "    HAS_CE = True\n",
    "except Exception:\n",
    "    HAS_CE = False\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "except Exception:\n",
    "    HAS_SHAP = False\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "# Paths\n",
    "REPO_ROOT   = Path(\"..\").resolve()\n",
    "TABLES_DIR  = REPO_ROOT / \"outputs\" / \"tables\"\n",
    "FIG_DIR     = REPO_ROOT / \"outputs\" / \"figures\"\n",
    "MODEL_DIR   = REPO_ROOT / \"outputs\" / \"models\"\n",
    "for p in [TABLES_DIR, FIG_DIR, MODEL_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH   = TABLES_DIR / \"master_jobs_ready.csv\"  # Assumption from brief\n",
    "\n",
    "# Artifacts\n",
    "MODEL_PATH          = MODEL_DIR / \"salary_predictor.pkl\"\n",
    "FEATURES_MANIFEST   = MODEL_DIR / \"salary_features.json\"\n",
    "METRICS_CSV         = TABLES_DIR / \"salary_model_metrics.csv\"\n",
    "\n",
    "print(\"✅ Environment ready.\")\n",
    "print(\"Data path ->\", DATA_PATH)\n",
    "print(\"Figures   ->\", FIG_DIR)\n",
    "print(\"Models    ->\", MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully from: ..\\data\\processed\\cleaned_master.csv\n",
      "Shape: (36167, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_category</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>work_setting</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "      <th>__source__</th>\n",
       "      <th>job_id</th>\n",
       "      <th>category</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_skill_set</th>\n",
       "      <th>salary_usd</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>required_skills</th>\n",
       "      <th>education_required</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>industry</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>application_deadline</th>\n",
       "      <th>job_description_length</th>\n",
       "      <th>benefits_score</th>\n",
       "      <th>company_name</th>\n",
       "      <th>salary_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>Machine Learning Engineer  in office</td>\n",
       "      <td>Analysis</td>\n",
       "      <td>EUR</td>\n",
       "      <td>186597.0</td>\n",
       "      <td>136086.0</td>\n",
       "      <td>US</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>Remote</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "      <td>dataset1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>Statistician  (Remote)</td>\n",
       "      <td>ML/AI</td>\n",
       "      <td>JPY</td>\n",
       "      <td>110630.0</td>\n",
       "      <td>67982.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>EX</td>\n",
       "      <td>FL</td>\n",
       "      <td>Remote</td>\n",
       "      <td>IN</td>\n",
       "      <td>M</td>\n",
       "      <td>dataset1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>ML/AI</td>\n",
       "      <td>INR</td>\n",
       "      <td>61280.0</td>\n",
       "      <td>153309.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>CN</td>\n",
       "      <td>L</td>\n",
       "      <td>dataset1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year                             job_title job_category salary_currency    salary  salary_in_usd employee_residence experience_level employment_type  \\\n",
       "0     2022.0  Machine Learning Engineer  in office     Analysis             EUR  186597.0       136086.0                 US               MI              CT   \n",
       "1     2020.0                Statistician  (Remote)        ML/AI             JPY  110630.0        67982.0                 JP               EX              FL   \n",
       "2     2022.0           Machine Learning Engineer          ML/AI             INR   61280.0       153309.0                 UK               MI              CT   \n",
       "\n",
       "  work_setting company_location company_size __source__ job_id category job_description job_skill_set  salary_usd  remote_ratio required_skills  \\\n",
       "0       Remote               DE            L   dataset1    NaN      NaN             NaN           NaN         NaN           NaN             NaN   \n",
       "1       Remote               IN            M   dataset1    NaN      NaN             NaN           NaN         NaN           NaN             NaN   \n",
       "2       Hybrid               CN            L   dataset1    NaN      NaN             NaN           NaN         NaN           NaN             NaN   \n",
       "\n",
       "  education_required  years_experience industry posting_date application_deadline  job_description_length  benefits_score company_name  salary_local  \n",
       "0                NaN               NaN      NaN          NaN                  NaN                     NaN             NaN          NaN           NaN  \n",
       "1                NaN               NaN      NaN          NaN                  NaN                     NaN             NaN          NaN           NaN  \n",
       "2                NaN               NaN      NaN          NaN                  NaN                     NaN             NaN          NaN           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen target: salary\n",
      "\n",
      "Target summary statistics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count      5000.000000\n",
       "mean     102046.307200\n",
       "std       70853.626492\n",
       "min     -198754.000000\n",
       "10%       38460.300000\n",
       "25%       64295.500000\n",
       "50%      110636.000000\n",
       "75%      153104.750000\n",
       "90%      180022.300000\n",
       "95%      189861.600000\n",
       "99%      197570.090000\n",
       "max      199924.000000\n",
       "Name: salary, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkwAAAGGCAYAAACJ/96MAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPBJJREFUeJzt3Qd4FOX69/E7tCSUgNSAdOkdQRFBRSmhiCAcC1KVgw0sNH1RpCoIKqAcinoochRRpBxFehcpUkUBkaaAdIRQEyCZ97qf/9m9dtNmk2yyJd/PdQ2b3ZmdfWZ3kv3xtAmxLMsSAAAAJCtb8qsAAACgCEwAAAA2CEwAAAA2CEwAAAA2CEwAAAA2CEwAAAA2CEwAAAA2CEwAAAA2CEwAAAA2CEwAvK5JkyZmcfjjjz8kJCREZs6cmeGvra+hr6Wv6VC2bFl5+OGHJTOsXbvWvL7eBpvM/BwBf0NgAjKAfql4svjbl+rGjRtl2LBhcvHiRfEHkydP9tsvZ38uGwDvy5EB+wSyvP/85z9u92fNmiUrVqxI9HjVqlXF3wLT8OHDpUePHlKgQAGv7bdMmTJy/fp1yZkzZ6pDSeHChU15PNW1a1d58sknJTQ0NA0lTX/Z7r//fnOsuXLlytDXB5C5CExABujSpYvb/c2bN5vAlPDxtNDrZcfExEh4eLgECq1NCwsLy9DXuHr1quTJk0eyZ89uFl/Jli1bhh9rsHB8ZkAgoEkO8JEZM2bIQw89JEWLFjW1IdWqVZMpU6Yk2s7R/2bZsmVSv359E5Q+/vhjs+7PP/+URx55xHzp6H769u1rtkuquW/Lli3SsmVLyZ8/v+TOnVseeOAB+fHHH53rtSlu4MCB5udy5co5mw1d+wIl5ZNPPpE77rjDlOvuu++WH374waO+L6dOnZKnn35aSpYsaY6/ePHi0q5dO+fr6XHv2bNH1q1b5yyLo1+Uo5+SrnvxxRfNset+XNclVe7ly5dLnTp1TKDR93v+/Plu6/U90OcmlHCfKZUtuT5Mc+fOlXr16pn3SWumNDz/9ddfbttobVXevHnN4+3btzc/FylSRAYMGCBxcXFu2548eVJ+++03uXnzptiZM2eOee18+fJJRESE1KxZUz788EPn+r///tu8hj6ur6nbtGrVSn7++Wfbfe/evduUu3z58uZ9jYyMlGeeeUbOnz+f5Hu7d+9eeeqpp+S2226Txo0bm98DfXznzp2J9j1q1CgTfhO+T4AvUMME+IiGo+rVq5vAkyNHDvnuu+/Ml398fLz07t3bbdv9+/dLp06d5LnnnpNevXpJ5cqVzf/ONXDpF+crr7xivqhmz54ta9asSfRaq1evNl+A+qU5dOhQUwviCGwacDTodOjQQX7//Xf58ssvZfz48eZLXekXdnKmTZtmynTvvffKq6++KocPHzbHU7BgQSlVqlSKx9+xY0cTOl566SUTQM6cOWNq4Y4ePWruT5gwwazTL/A333zTPKdYsWJu+9D3S8s3ZMgQ836k5MCBA/LEE0/I888/L927dzfH/9hjj8nSpUulefPmkhqelC1h4NJweNddd8no0aPl9OnTJrBoYNWg4Nr8qcEoKipKGjRoIO+//76sXLlSPvjgAxNKX3jhBed2gwYNks8++0yOHDli3q/k6Huq507Tpk1lzJgx5rF9+/aZ19bzRunntnDhQvN+aFjW8mko11CtAadEiRIp7l+fr8en56B+phqi9VZrVhMGUH2NihUrmjCktaX/+Mc/zPn+xRdfSN26dd221cc0iN5+++0pfBpAJrEAZLjevXtbCX/drl27lmi7qKgoq3z58m6PlSlTxjx36dKlbo9/8MEH5vGFCxc6H7t+/bpVpUoV8/iaNWvMY/Hx8VbFihXNvvVn19cvV66c1bx5c+dj7733nnnukSNHbI/pxo0bVtGiRa06depYsbGxzsc/+eQTs48HHnjA+ZjuTx+bMWOGuX/hwgVzX18vJdWrV3fbj4PuR5/fuHFj69atW0mucz0Gx3s4b94852PR0dFW8eLFrbp16zofGzp0aKLPKbl9Jlc2fd9d33/H+1SjRg3z+TgsWrTIbDdkyBDnY927dzePjRgxwm2fWsZ69eq5PebY1u6zeuWVV6yIiIhE75OrmJgYKy4uzu0x3W9oaKhbWRJ+jsmdx19++aXZbv369Yne206dOiXaXh8rUaKEWxl27NiR6LUAX6JJDvAR1z5I0dHRcu7cOfM/ev3fut53pf/r11oHV1ozov/z1hodB20S0RooV7t27TK1K9oMos0k+jq6aI2M1jqsX7/e1Gql1rZt20ytkNbYuHZw1uYZbfazO3Z9jjZbXbhwQdJKj9XT/kpaS/Loo48672uzU7du3UwNjzYPZhTH+6S1Ya59m9q0aSNVqlSR77//PtFz9D11dd9995nzImGtldbQpFS7pLT2Sj9rrQlKjjaJaq2jo4ZLzxOtPdOazB07dnh8HmvfOj237rnnHnM/qecmPDaln8OJEyfcake1dkn3rTWRgD8gMAE+ok0izZo1M/2P9EtNm5beeOMNsy6pwJSQ9l/SZpqETR4VKlRwu69hSWkzlL6G6/Lvf/9bYmNjE72eJ/T1lTavuNKRcNqfJSX6Ba3NQ0uWLDFNWTqybOzYsakOLkm9L8nR9yXhe1WpUiVza9dPKz0c75OGj4Q0MDnWO2ioStgMqv190hosNajpcWqTrPbz0v5FGrZdaWDWZlj9LPWz0eZYLYP2T7I7N7T/kzbt6eeoAUef5/hcknpuUp+ZNolqHzYNSY7yaNOw9mnTfleAP6APE+ADhw4dMrU7+oU5btw4099Ha1wWL15svrgS1vikZ0ScY1/vvfee6fCcFK1NyGza56lt27am74x2VH/rrbdM/x7tb5WwL0tyvD1SMKkO3yphh+uM5O0RftohXmsZ9T3WgKqL9t/SWh3tA6W0P5G+/xqmRo4cafqgaY2TfkZ2tY+PP/64mY5CBwzo+aXnkj5HBxgk9dykPjM9Zq0B/fTTT810DfqfCa1x8saoUsBbCEyAD2gHb63Z+fbbb6V06dLOx5PqsJ3S3EbaIVebZVy/6A8ePOi2ndZCOZqgtEYrLYEhudd31GBp53EHHbWlHZFr165tuw8tW//+/c2i+9EvXO3g/Pnnn6e6PHb0fUn4Xmknd+Vo1tKaHKUTd7p2xE5YC5SasjneJ+247/o+OR5zrM9IGsY1nOqiIUZrnbRTt4YkrXn75ptv5MEHHzSd+F3p++Do/J8UrfVatWqVmbtLO94nrNVMDQ1w+tnr74aGOq2pStgMDfgSTXKADzhqEfQL3EGbL/R//p7SLxMdbq2hy7UPif4v3ZWOjNNgoiOurly5kmg/Z8+edf7smBPHk5m+dYoD/VKbOnWq3Lhxw61vjd3zr127ZsrqSsuozS8aJF3L461Zx7XGYsGCBc77ly5dMhOKakjT0V2OMijt1+Wg/X8cNTGuPC2bvk9ay6Pvk+uxaSjQ0WralyktPJ1WIOHwfq05qlWrlvnZUR49H13PRcc0CHbD+ZM6jx2jCFNLy6SLNhPPmzfPTD6qo0cBf8HZCPhAixYtnP/r12H5GmQ06OgXq34RekKf969//csMGdc+JI4+II6OxY4aEP2C1C8h7cOi0xjo8G/tLK5fhlqjpTVP+r96R7hSOlRev7C0P5KWManJBXXd22+/bcqhNSc6ZF9rljT02fVh0podbZLU5hydD0m/GDXM6HB2fV0HLY9Ov6CvozUh+v4krKXxlPbj6dmzp2zdutX0t5k+fbp5PdeQqp+L1vjpdtrEpIFAt9NgqNMduPK0bPo+aX8tfd+1U79+Xo5pBbRmS+fOSgtPpxX45z//afoZadm0D5PWlk2cONEERcdM8zrP14gRI0wZdYqIX375xZxLdp+jnjuO/mca3PS80rmutExpobVMOh+UojkOfsenY/SALDytwLfffmvVqlXLCgsLs8qWLWuNGTPGmj59epJD4tu0aZPkfg8fPmzWhYeHW0WKFLH69+9vhs7rPjZv3uy27c6dO60OHTpYhQoVMsPFdb+PP/64tWrVKrftRo4cad1+++1WtmzZPBq2PnnyZDM9ge6zfv36Zii5DrdPaVqBc+fOmfdEp0DIkyePlT9/fqtBgwbW119/7bbvU6dOmePLly+f21QFjmH+W7duTVSe5KYV0P0sW7bMvOdaVn3tuXPnJnr+9u3bTVly5cpllS5d2ho3blyS+0yubAmnFXD46quvzPQA+toFCxa0OnfubB0/fjzRVAH6fiSU1HQHnk4r8M0331gtWrQwUxs4jum5556zTp486TatgJ47Os2CnkuNGjWyNm3aZPs5Kj2GRx991CpQoID5HB977DHrxIkTZjstd8JjOHv2bLJl1TJlz57dqlSpUorHBPhCiP7j69AGwHu0OURrLY4fP86EfwgoOiWB1pRqfyjtXwX4E/owAQFML/LqSvsFaWdeHR5OWEKg0f5vOiJRL6AM+Bv6MAEBTC9non1utD+KdhrX0WXaEdgxnw0QCHQqCR3x+c4775hr6NlNxgn4Ak1yQIA3v2mHbp14Uf9nrh2oX3vtNdMBGwgUer04ncupUaNGJvRTOwp/RGACAACwQR8mAAAAGwQmAAAAG3T6/t+1tnQWYJ1l2JuXYgAAAP5FeyJdvnxZSpQoYSb29RSB6X+XTNCLnwIAgKzh2LFjZvZ7TxGYREzNkuPN06n+AQBAcLp06ZKpJHF893uKwORyzS0NSwQmAACCX0gqu+DQ6RsAAMAGgQkAAMAGgQkAAMAGgQkAAMAGgQkAAMAGgQkAAMAGgQkAAMAGgQkAAMAGgQkAAMAGgQkAAMAGgQkAAMAG15IDAMDG0aNH5dy5cx5vX7hwYSldunSGlgmZi8AEAIBNWKpcparEXL/m8XPCwnPL/t/2BVxoIhgmj8AEAEAKNEBoWCr0cH/JWaiU7fY3zx+T84s+MM8LpDCRlYJhWhCYAADwgIal0MgKEqyySjBMKwITAADIMsEwrRglBwAAYIPABAAA4M+BacqUKVKrVi2JiIgwS8OGDWXJkiXO9TExMdK7d28pVKiQ5M2bVzp27CinT59O1EmtTZs2kjt3bilatKgMHDhQbt265YOjAQAAwcqnfZhKliwp7777rlSsWFEsy5LPPvtM2rVrJzt37pTq1atL37595fvvv5e5c+dK/vz5pU+fPtKhQwf58ccfzfPj4uJMWIqMjJSNGzfKyZMnpVu3bpIzZ04ZNWqULw8NAPxmODdDxYEAD0xt27Z1u//OO++YWqfNmzebMDVt2jSZPXu2PPTQQ2b9jBkzpGrVqmb9PffcI8uXL5e9e/fKypUrpVixYlKnTh0ZOXKkvP766zJs2DDJlSuXj44MADyXkcO5GSqe/iC5b9++TCkP/JvfjJLT2iKtSbp69appmtu+fbvcvHlTmjVr5tymSpUq5hd406ZNJjDpbc2aNU1YcoiKipIXXnhB9uzZI3Xr1k3ytWJjY83icOnSpQw+OgDwzXBuhop7L0gia/N5YPrll19MQNL+StpPacGCBVKtWjXZtWuXqSEqUKCA2/Yajk6dOmV+1lvXsORY71iXnNGjR8vw4cMz5HgAwB+HczNUPO1B8vrhbRL9w+eZVjb4J58HpsqVK5twFB0dLd988410795d1q1bl6GvOWjQIOnXr59bDVOpUvb/8wIABBdPgqTWugE+D0xai1Shwv+drPXq1ZOtW7fKhx9+KE888YTcuHFDLl686FbLpKPktJO30tuffvrJbX+OUXSObZISGhpqFgAAgICchyk+Pt70L9LwpKPdVq1a5Vy3f/9+0+6sTXhKb7VJ78yZM85tVqxYYaYo0GY9AACAgK9h0qaxVq1amY6Fly9fNiPi1q5dK8uWLTPTCPTs2dM0nRUsWNCEoJdeesmEJO3wrVq0aGGCUdeuXWXs2LGm39LgwYPN3E3UIAEAgKAITFozpPMm6fxJGpB0EksNS82bNzfrx48fL9myZTMTVmqtk46Amzx5svP52bNnl0WLFplRcRqk8uTJY/pAjRgxwodHBQAAgo1PA5POs5SSsLAwmTRpklmSU6ZMGVm8eHEGlA4AAMBPOn0DANLGkwkVmXQR8A4CEwAEmLgrF0RCQqRLly6+LgqQZRCYACDAxMdeEbEsJl0EMhGBCQACFJMuAll4HiYAAAB/Qw0TACDNdDJhvS6bpwoXLhzUF/VF8CIwAQDSHJYqV6lqLmLrqbDw3LL/t31ZIjR5OkKREBkYCEwAgDTRmiUNS550Pnf0pzq/6APzvGAOCKkdxZiVQmQgIzABADK883lWkppRjFklRAYDAhMAABmAIBlcGCUHAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg1FyAAC/xCzi8CcEJgCA38lqs4h7Oiu4Ihj6BoEJAOB3ssos4qmdFTzQg2EgIzABAPxWsE/+mJpZwQM5GAYDAhMAwO+an1LTRBUMgj0YBgMCEwDAb5ufAH9BYAIA+F3z0/XD2yT6h88zrWyBxtMaODqIew+BCQDgd81P2lcH6a+lo4O49xCYAAAIwlo6Ooh7F4EJAIAAQyfxzMelUQAAAGwQmAAAAGwQmAAAAGwQmAAAAGwQmAAAAGwwSg4AkOUmdMxKl17hPfEOAhMAIOBx2ZXEeE+8i8AEAMhSEzpmlUuv8J54F4EJAJDlJnTMSpde4T3xDjp9AwAA+HNgGj16tNx1112SL18+KVq0qLRv317279/vtk2TJk0kJCTEbXn++efdtjl69Ki0adNGcufObfYzcOBAuXXrViYfDQAAWc++fftkx44dtot+VwcynzbJrVu3Tnr37m1CkwacN954Q1q0aCF79+6VPHnyOLfr1auXjBgxwnlfg5FDXFycCUuRkZGyceNGOXnypHTr1k1y5swpo0aNyvRjAgAgK4hLZafysPDcsv+3fQF7IWCfBqalS5e63Z85c6apIdq+fbvcf//9bgFJA1FSli9fbgLWypUrpVixYlKnTh0ZOXKkvP766zJs2DDJlStXhh8HAABZTXwqOpVr/6jziz6Qc+fOBWxg8qs+TNHR0ea2YMGCbo9/8cUXUrhwYalRo4YMGjRIrl275ly3adMmqVmzpglLDlFRUXLp0iXZs2dPJpYeAICsJ+f/OpWntHgySs/f+c0oufj4eHn11VelUaNGJhg5PPXUU1KmTBkpUaKE7N6929QcaT+n+fPnm/WnTp1yC0vKcV/XJSU2NtYsDhquAAAA/D4waV+mX3/9VTZs2OD2+LPPPuv8WWuSihcvLk2bNpVDhw7JHXfckebO5sOHD093mQEAQNbgF4GpT58+smjRIlm/fr2ULFkyxW0bNGhgbg8ePGgCk/Zt+umnn9y2OX36tLlNrt+TNuv169fPrYapVKnAry4EAMCf7UvF5Ve0K44/9XfyaWCyLEteeuklWbBggaxdu1bKlStn+5xdu3aZW61pUg0bNpR33nlHzpw5YzqMqxUrVkhERIRUq1YtyX2EhoaaBQAA+OdlWsL8bFRdDl83w82ePVv++9//mrmYHH2O8ufPL+Hh4abZTde3bt1aChUqZPow9e3b14ygq1WrltlWpyHQYNS1a1cZO3as2cfgwYPNvglFAAAE3mVabvrhqDqfBqYpU6Y4J6d0NWPGDOnRo4eZEkCnC5gwYYJcvXrVNJt17NjRBCKH7Nmzm+a8F154wdQ26fxN3bt3d5u3CQAABM5lWvyRz5vkUqIBSSe3tKOj6BYvXuzFkgEAAPjpPEwAAAD+iMAEAABgg8AEAABgg8AEAAAQCBNXAgACb4LB1ExCCAQ6AhMAIF0TDAJZAYEJAJCmCQavH94m0T98nmllA3yJwAQASNMEgzobM5BV0OkbAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADAnwPT6NGj5a677pJ8+fJJ0aJFpX379rJ//363bWJiYqR3795SqFAhyZs3r3Ts2FFOnz7tts3Ro0elTZs2kjt3brOfgQMHyq1btzL5aAAAQLDyaWBat26dCUObN2+WFStWyM2bN6VFixZy9epV5zZ9+/aV7777TubOnWu2P3HihHTo0MG5Pi4uzoSlGzduyMaNG+Wzzz6TmTNnypAhQ3x0VAAAINjk8OWLL1261O2+Bh2tIdq+fbvcf//9Eh0dLdOmTZPZs2fLQw89ZLaZMWOGVK1a1YSse+65R5YvXy579+6VlStXSrFixaROnToycuRIef3112XYsGGSK1cuHx0dAAAIFn7Vh0kDkipYsKC51eCktU7NmjVzblOlShUpXbq0bNq0ydzX25o1a5qw5BAVFSWXLl2SPXv2JPk6sbGxZr3rAgAA4PeBKT4+Xl599VVp1KiR1KhRwzx26tQpU0NUoEABt201HOk6xzauYcmx3rEuub5T+fPndy6lSpXKoKMCAABZNjAdPnzY6wXRvky//vqrzJkzRzLaoEGDTG2WYzl27FiGvyYAAMhigalChQry4IMPyueff25GsaVXnz59ZNGiRbJmzRopWbKk8/HIyEjTmfvixYtu2+soOV3n2CbhqDnHfcc2CYWGhkpERITbAgAA4NXAtGPHDqlVq5b069fPhJLnnntOfvrpp1Tvx7IsE5YWLFggq1evlnLlyrmtr1evnuTMmVNWrVrlfEynHdBpBBo2bGju6+0vv/wiZ86ccW6jI+40BFWrVi0thwcAAJD+wKQj0T788EMzxH/69Oly8uRJady4sel7NG7cODl79qzHzXBaS6Wj4HQuJu1zpMv169fNeu1f1LNnTxPMtPZJO4E//fTTJiTpCDml0xBoMOratav8/PPPsmzZMhk8eLDZt9YkAQAA+LTTd44cOcycSDpH0pgxY+TgwYMyYMAA04m6W7duJkilZMqUKaYPUZMmTaR48eLO5auvvnJuM378eHn44YfNhJU61YDWaM2fP9+5Pnv27KY5T281SHXp0sW89ogRI9JzaAAAAN6Zh2nbtm2mhkk7aufJk8eEJa0ROn78uAwfPlzatWuXYlOdNsnZCQsLk0mTJpklOWXKlJHFixen+TgAAAC8Hpi02U0nkNT+RK1bt5ZZs2aZ22zZ/q/CSvsi6SSUZcuWTcvuAQAAAj8waVPaM888Iz169DBNaEnRGbt1lm4AAIAsGZgOHDhgu41OONm9e/e07B4AACDwO31rc5x29E5IH9OL3wIAAEhWD0x6aZHChQsn2Qw3atQob5QLAAAgsAOTThyZcJJJx2g1XQcAACBZPTBpTdLu3bsTPa4TRxYqVMgb5QIAAAjswNSpUyd5+eWXzezbcXFxZtFLm7zyyivy5JNPer+UAAAAgTZKbuTIkfLHH39I06ZNzWzfKj4+3sywTR8mAAAQbNIUmHTKAL18iQYnbYYLDw+XmjVrmj5MAAAAwSZdl0apVKmSWQAAAIJZmgKT9lnSS5+sWrVKzpw5Y5rjXGl/JgAAgCwdmLRztwamNm3aSI0aNSQkJMT7JQMAAAjkwDRnzhz5+uuvzQV3AQAAgl22tHb6rlChgvdLAwAAECyBqX///vLhhx+KZVneLxEAAEAwNMlt2LDBTFq5ZMkSqV69uuTMmdNt/fz5871VPgAAgMAMTAUKFJBHH33U+6UBAAAIlsA0Y8YM75cEAAAgmPowqVu3bsnKlSvl448/lsuXL5vHTpw4IVeuXPFm+QAAAAKzhunPP/+Uli1bytGjRyU2NlaaN28u+fLlkzFjxpj7U6dO9X5JAQAAAqmGSSeurF+/vly4cMFcR85B+zXp7N8AAACS1WuYfvjhB9m4caOZj8lV2bJl5a+//vJW2QAAAAK3hkmvHafXk0vo+PHjpmkOAAAgmKQpMLVo0UImTJjgvK/XktPO3kOHDuVyKQAAIOikqUnugw8+kKioKKlWrZrExMTIU089JQcOHJDChQvLl19+6f1SAgAABFpgKlmypPz888/mIry7d+82tUs9e/aUzp07u3UCBwAAyLKByTwxRw7p0qWLd0sDAAAQLIFp1qxZKa7v1q1bWssDAAAQHIFJ52FydfPmTbl27ZqZZiB37twEJgAAEFTSNEpOJ6x0XbQP0/79+6Vx48Z0+gYAAEEnzdeSS6hixYry7rvvJqp9AgAACHReC0yOjuB6AV4AAADJ6n2Yvv32W7f7lmXJyZMn5V//+pc0atTIW2UDAAAI3MDUvn17t/s603eRIkXkoYceMpNaAgAABJM0X0vOddHryp06dUpmz54txYsX93g/69evl7Zt20qJEiVM6Fq4cKHb+h49epjHXZeWLVu6bfP333+bCTMjIiKkQIECZgJN7YQOAADgl32YUuvq1atSu3ZtmTRpUrLbaEDS5j7HknAUnoalPXv2yIoVK2TRokUmhD377LOZUHoAAJBVpKlJrl+/fh5vO27cuGTXtWrVyiwpCQ0NlcjIyCTX7du3T5YuXSpbt26V+vXrm8cmTpxoLgD8/vvvm5orAAAAnwSmnTt3mkUnrKxcubJ57Pfff5fs2bPLnXfe6dxOm9DSa+3atVK0aFG57bbbTB+pt99+WwoVKmTWbdq0yTTDOcKSatasmWTLlk22bNkijz76aLpfHwAAIE2BSfsd5cuXTz777DMTZJROYPn000/LfffdJ/379/dK4bQ5rkOHDlKuXDk5dOiQvPHGG6ZGSoOShjPtN6Vhyu2AcuSQggULmnXJiY2NNYvDpUuXvFJeAAAQnNIUmHQk3PLly51hSenPWvvTokULrwWmJ5980vlzzZo1pVatWnLHHXeYWqemTZumeb+jR4+W4cOHe6WMAAAg+KWp07fWyJw9ezbR4/rY5cuXJaOUL19eChcuLAcPHjT3tW/TmTNn3La5deuWGTmXXL8nNWjQIImOjnYux44dy7AyAwCALBqYtG+QNr/Nnz9fjh8/bpZ58+aZIf3ahJZR9HXOnz/vnLqgYcOGcvHiRdm+fbtzm9WrV5upDho0aJBiR3KdhsB1AQAA8GqT3NSpU2XAgAHy1FNPmY7fZkc5cpjA9N5773m8H50vyVFbpI4cOSK7du0yfZB00Wazjh07mtoi7cP02muvSYUKFSQqKspsX7VqVdPPqVevXqZMWpY+ffqYpjxGyAEAAJ8Gpty5c8vkyZNNONIgo7RvUZ48eVK1n23btsmDDz6YaLqC7t27y5QpU2T37t2mY7nWImkA0v5RI0eONDVEDl988YUJSdqnSUfHacD66KOP0nJYAAAA3gtMDo7JJO+//34JDw8315RLzVQCTZo0Mc9JzrJly2z3oTVROsM4AACAX/Vh0n5EWqNTqVIlM0mkhialTXLeGiEHAAAQ0IGpb9++kjNnTjl69KhpnnN44oknzMzbAAAAktWb5HQOJm0uK1mypNvjFStWlD///NNbZQMAAAjcGia9aK5rzZKDzn/k2iEbAAAgywYmvfzJrFmznPe1o7fOfTR27Fi3UW8AAABZtklOg5F2+tZpAW7cuGHmR9qzZ4+pYfrxxx+9X0oAAIBAq2GqUaOG/P7779K4cWNp166daaLTGb537txp5mMCAADI0jVMOpu2zq6tM2u/+eabGVMqAACAQK5h0ukEdAZuAACArCJNTXJdunSRadOmeb80AAAAwdLp+9atWzJ9+nRZuXKl1KtXL9E15MaNG+et8gEAAARWYDp8+LCULVtWfv31V7nzzjvNY9r521VqriUHAAAQdIFJZ/LW68atWbPGeSmUjz76SIoVK5ZR5QMAAAisPkyWZbndX7JkiZlSAAAAIJilqdN3cgEKAABAsnpg0v5JCfso0WcJAAAEuxyprVHq0aOH8wK7MTEx8vzzzycaJTd//nzvlhIAACBQAlP37t0TzccEAAAQ7FIVmGbMmJFxJQEAAAjGTt8AAABZAYEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADAnwPT+vXrpW3btlKiRAkJCQmRhQsXuq23LEuGDBkixYsXl/DwcGnWrJkcOHDAbZu///5bOnfuLBEREVKgQAHp2bOnXLlyJZOPBAAABDOfBqarV69K7dq1ZdKkSUmuHzt2rHz00UcydepU2bJli+TJk0eioqIkJibGuY2GpT179siKFStk0aJFJoQ9++yzmXgUAAAg2OXw5Yu3atXKLEnR2qUJEybI4MGDpV27duaxWbNmSbFixUxN1JNPPin79u2TpUuXytatW6V+/fpmm4kTJ0rr1q3l/fffNzVXAAAAQduH6ciRI3Lq1CnTDOeQP39+adCggWzatMnc11tthnOEJaXbZ8uWzdRIAQAABHwNU0o0LCmtUXKl9x3r9LZo0aJu63PkyCEFCxZ0bpOU2NhYszhcunTJy6UHAADBxG9rmDLS6NGjTW2VYylVqpSviwQAAPyY3wamyMhIc3v69Gm3x/W+Y53enjlzxm39rVu3zMg5xzZJGTRokERHRzuXY8eOZcgxAACA4OC3galcuXIm9Kxatcqt6Uz7JjVs2NDc19uLFy/K9u3bndusXr1a4uPjTV+n5ISGhpppCFwXAAAAv+zDpPMlHTx40K2j965du0wfpNKlS8urr74qb7/9tlSsWNEEqLfeesuMfGvfvr3ZvmrVqtKyZUvp1auXmXrg5s2b0qdPHzOCjhFyAAAgKALTtm3b5MEHH3Te79evn7nt3r27zJw5U1577TUzV5POq6Q1SY0bNzbTCISFhTmf88UXX5iQ1LRpUzM6rmPHjmbuJgAAgKAITE2aNDHzLSVHZ/8eMWKEWZKjtVGzZ8/OoBICAAD4cR8mAAAAf0FgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAAsEFgAgAACOTANGzYMAkJCXFbqlSp4lwfExMjvXv3lkKFCknevHmlY8eOcvr0aZ+WGQAABB+/DkyqevXqcvLkSeeyYcMG57q+ffvKd999J3PnzpV169bJiRMnpEOHDj4tLwAACD45xM/lyJFDIiMjEz0eHR0t06ZNk9mzZ8tDDz1kHpsxY4ZUrVpVNm/eLPfcc48PSgsAAIKR39cwHThwQEqUKCHly5eXzp07y9GjR83j27dvl5s3b0qzZs2c22pzXenSpWXTpk0p7jM2NlYuXbrktgAAAARkYGrQoIHMnDlTli5dKlOmTJEjR47IfffdJ5cvX5ZTp05Jrly5pECBAm7PKVasmFmXktGjR0v+/PmdS6lSpTL4SAAAQCDz6ya5Vq1aOX+uVauWCVBlypSRr7/+WsLDw9O830GDBkm/fv2c97WGidAEAAACsoYpIa1NqlSpkhw8eND0a7px44ZcvHjRbRsdJZdUnydXoaGhEhER4bYAAAAERWC6cuWKHDp0SIoXLy716tWTnDlzyqpVq5zr9+/fb/o4NWzY0KflBAAAwcWvm+QGDBggbdu2Nc1wOmXA0KFDJXv27NKpUyfT96hnz56maa1gwYKmluill14yYYkRcgAAIMsEpuPHj5twdP78eSlSpIg0btzYTBmgP6vx48dLtmzZzISVOvItKipKJk+e7OtiAwCAIOPXgWnOnDkprg8LC5NJkyaZBQAAIKMEVB8mAAAAXyAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2CAwAQAA2MhhtwHS7+jRo3Lu3DmPti1cuLCULl06w8sEAAA8R2DKhLBUuUpVibl+zaPtw8Jzy/7f9hGaAADwIwSmDKY1SxqWCj3cX3IWKpXitjfPH5Pziz4wzyEwAQDgPwhMmUTDUmhkBV8XAwAApAGBCV7pe6XofwUACFYEpgCXUaEmtX2v/Kn/FUEPAOBtBKYAlpGhJjV9r/yp/1UgBz0AgP8iMPmhffv2ebxdRoeaQOt7FahBLy2oSQOAzENg8iNxVy6IhIRIly5dUvW8QAs1GRkOHGEzI98Tf5hXi5o0AMhcBCY/Eh97RcSyPK4duX54m0T/8HmG1GB5WsuVGaHj5MmT0vEfj0lszHXxtdQGldDQMJk37xspXry4VwNWRtekUXuVfql5DzP69w1A+hGY/JCntSP6JZgZNVj+UDuiPAkHaQ2RnkpNUIk5vkcurv63PPzwwxlWC5QRNWnUXvnuHAfgvwhMWUhqarAyuvYqNbUjjrJ4Eg5SGyJdy5Sa7TwuSypqDDOjP1VGfD6B3A8so6S2BjCjgz6A9CMwZUEZETzSUnuVUTVp/lbrltpaoIxoMs3Izwf+fY4D8A4CEwKm9iqQ+435OrwF6ucDAP6CwASvyshms2CvCciMUOMPzZqKTuIAAg2BCfAzgRY601IzRidxAIGGwAQgU5s16SQOIBARmAB4BZ3EAQSzbBIkJk2aJGXLlpWwsDBp0KCB/PTTT74uEgAACBJBEZi++uor6devnwwdOlR27NghtWvXlqioKDlz5oyviwYAAIJAUASmcePGSa9eveTpp5+WatWqydSpUyV37twyffp0XxcNAAAEgYAPTDdu3JDt27dLs2bNnI9ly5bN3N+0aZNPywYAAIJDwHf61pE2cXFxUqxYMbfH9f5vv/2W5HNiY2PN4hAdHW1uL1265PXyXbly5f9e89RBib8R49FQcU+2zejt2bd/lyVQ9222//u4udX/6Dh+P1Ki/wGKj4+33S4t22fUvvfv329uOQ/9c9/+VJZA3XeGl+V/fyf0b4S3v5sd+7MsK3VPtALcX3/9pUdsbdy40e3xgQMHWnfffXeSzxk6dKh5DgsLCwsLC0vWXI4dO5aqvBHwNUw6Y3D27Nnl9OnTbo/r/cjIyCSfM2jQINNJ3EH/x/j3339LoUKFJCQkxGsJtlSpUnLs2DGJiIiQYMVxBpescpxZ6Vg5zuDCcaaf1ixdvnxZSpQokarnBXxgypUrl9SrV09WrVol7du3dwYgvd+nT58knxMaGmoWVwUKFMiQ8ukHHcwntQPHGVyyynFmpWPlOIMLx5k++fPnT/VzAj4wKa0t6t69u9SvX1/uvvtumTBhgly9etWMmgMAAEivoAhMTzzxhJw9e1aGDBkip06dkjp16sjSpUsTdQQHAADIsoFJafNbck1wvqBNfjqRZsKmv2DDcQaXrHKcWelYOc7gwnH6Toj2/Pbh6wMAAPi9gJ+4EgAAIKMRmAAAAGwQmAAAAGwQmFz88ccf0rNnTylXrpyEh4fLHXfcYTqd6fXqXO3evVvuu+8+CQsLMxNrjR07NtG+5s6dK1WqVDHb1KxZUxYvXuy2XruO6ai+4sWLm9fSa98dOHDAbRudTLNz585mDgqdJ0rLlvBSEp6UJSnvvPOO3HvvveYixcnNQaWTeCZc5syZ47bN2rVr5c477zQd8ypUqCAzZ85MtJ9JkyZJ2bJlTRkbNGggP/30k9v6mJgY6d27t5k4NG/evNKxY8dEE5EePXpU2rRpY8pbtGhRGThwoNy6dcsrx+nJvv39OBPSciT87N59912/PY8zm91n5UvDhg1L9NnpZ+Dt88gb53RqrF+/Xtq2bWsmC9RjWrhwoc/+JnrjvE7rcfbo0SPR59uyZcuAO87Ro0fLXXfdJfny5TPnmM6D6LgkkD+eq56UxVZ6LksSbJYsWWL16NHDWrZsmXXo0CHrv//9r1W0aFGrf//+zm2io6OtYsWKWZ07d7Z+/fVX68svv7TCw8Otjz/+2LnNjz/+aGXPnt0aO3astXfvXmvw4MFWzpw5rV9++cW5zbvvvmvlz5/fWrhwofXzzz9bjzzyiFWuXDnr+vXrzm1atmxp1a5d29q8ebP1ww8/WBUqVLA6deqUqrIkZ8iQIda4ceOsfv36mXIkRU+PGTNmWCdPnnQuruU7fPiwlTt3brMPPc6JEyea4166dKlzmzlz5li5cuWypk+fbu3Zs8fq1auXVaBAAev06dPObZ5//nmrVKlS1qpVq6xt27ZZ99xzj3Xvvfc619+6dcuqUaOG1axZM2vnzp3W4sWLrcKFC1uDBg1K93F6su9AOM6EypQpY40YMcLts7ty5YpfnseZzZPPypf00k3Vq1d3++zOnj3r1fPIW+d0amg53nzzTWv+/Pnmb8uCBQvc1mfW30RvnddpPc7u3bub43D9fP/++2+3bQLhOKOiosz3g77+rl27rNatW1ulS5d2+zvjT+eqXVk8QWCyoSebnkAOkydPtm677TYrNjbW+djrr79uVa5c2Xn/8ccft9q0aeO2nwYNGljPPfec+Tk+Pt6KjIy03nvvPef6ixcvWqGhoebEV3pi6C/b1q1b3QJdSEiIuX6ep2Wxoyd8SoEp4S+7q9dee838YXf1xBNPmF8kB72eX+/evZ334+LirBIlSlijR492Hrf+Es+dO9e5zb59+8xrb9q0ydzXX6Js2bJZp06dcm4zZcoUKyIiwu3Y03Kcnuw7kI7TNTCNHz8+2fX+dB5nNrvPyh8Ck35ZJsVb55E3zun0SPi3JTP/JnrjvE7rcToCU7t27ZJ9TiAepzpz5owp97p16/zuXPWkLJ6gSc5GdHS0FCxY0Hl/06ZNcv/995tLsjhERUWZqsgLFy44t9GqTVe6jT6ujhw5YibYdN1Gp2nXakTHNnqrVbE6e7mDbq9XS9+yZYvHZUkvrcLU6/XpDOrTp093u7qz3XFqU6Zekd51Gy2/3ndso+tv3rzpto1WIZcuXdrtvdDqZNeJSPV19FpDe/bsSdfxebLvQD1ObYLT6ue6devKe++951bN7U/ncWby5LPyB9osok065cuXN00z2mzhzfPIG+e0N2Xm30RvnNfppU1M2vxUuXJleeGFF+T8+fPOdYF6nNHR0ebW8X3pT+eqJ2XxBIEpBQcPHpSJEyfKc88953xMT7CEM4g77uu6lLZxXe/6vOS20V8oVzly5DAno93ruL5GeowYMUK+/vprWbFihWnvffHFF8374ZDc6+vJfv36dTl37pzExcXZHqf+0ifsX5Rwm4w6zvR8nv58nC+//LLpb7ZmzRpz/o4aNUpee+01vzyPM5Mnn5Wv6ReW9tHQqxVMmTLFfLFpXxW9WKi3ziNvnNPelJl/E71xXqeH9leaNWuWud7pmDFjZN26ddKqVSvzfgfqccbHx8urr74qjRo1kho1ajj37y/nqidlyVIzfafk//2//2dOzJTs27fPrWPlX3/9ZU7sxx57THr16iWBdpzVqlXz6DhT8tZbbzl/1loKvT6f1lTol7G/HGfr1q3TfZzBeB7r9RUdatWqZf5YaHDSjpr+NHMuEtMvT9fPTgNUmTJlzH9etGMuAtuTTz7p/FlrV/Qz1gFGWuvUtGlTCUS9e/eWX3/9VTZs2CDBLEsEpv79+5uRCSnRqm+HEydOyIMPPmhGV33yySdu20VGRibqWe+4r+tS2sZ1veMxHZ3guo1eB8+xzZkzZ9z2oU0qOnoiudfR46xatao51s2bNyd5NWbX40wt/cM9cuRIiY2NNV+6yR2njuzQP+zZs2c3i917oVWqFy9edEv/CbdxHfGgx6lVq82bN5d58+YlGQ49Pc6E+3a8tmOd49YXx5mwLKk9jxN+dnr+6EhQbQbwp/M4M2nzst1n5W/0fKlUqZKp8dZzPr3nkbfOaW/KqL+Jjn14+7z2Jv2d1fNSP18NTIF2nH369JFFixaZ0YElS5Z0Pu6Nv3mZ+ffXE1miSa5IkSLmf90pLY62YK1ZatKkidSrV09mzJhh2kJdNWzY0JwY2h7qoE1W+iV02223ObfR6lZXuo0+rnTaAv2QXLfR6kVtn3Zso7f64Wrbq8Pq1atN1ad++SVVFj1ObcPWsug2KR1nWuzatcsco6OGwu449bX0fXTdRsuv9x3b6PqcOXO6baPHoH02XN+LX375xflHRI/z8OHD5hdGh6Om5zgT7ttxDLpvRxDz1XEmLEtqzuOkPjs9lx1V/f50HmcmTz4rf6PDyQ8dOmS+1LxxHnnrnPamjPqbmFHntTcdP37c9GFyhJZAOU7LskxYWrBggSmf7s+VP52rnpTFIx53D88Cjh8/boZvNm3a1PzsOuzTQXvb63DOrl27muGUOpxRhzwmHM6ZI0cO6/333zc98XXUS1LDOXXYo05dsHv3bjNqIqkhtHXr1rW2bNlibdiwwapYsaLb0FJPypKcP//80wzjHD58uJU3b17zsy6XL18267/99lvr008/NWU+cOCAGZWh+9Zh+gmHew4cONAc56RJk5Ic7qmjLmbOnGlGfzz77LPmuF1HRehwTx2Ounr1ajPcs2HDhmZJOPS0RYsWZviq7r9IkSIeDbe3O05P9h0Ix+lq48aNZoSc7kOnx/j888/Nfrp16+aX53Fm8+Sz8iWdxmTt2rXWkSNHzGegQ651qLWOQvLWeeStczo19HfO8funXz063Yf+rL+jmfk30VvndVqOU9cNGDDAjMzSz3flypXWnXfeaY4jJiYmoI7zhRdeMCOP9Vx1/a68du2acxt/OlftyuIJAlOCoed6gie1uNL5Kho3bmw+oNtvv92cdAl9/fXXVqVKlczcEDok8vvvv3dbr0M633rrLXPS6340pO3fv99tm/Pnz5tfEv2i12GWTz/9tPOLPjVlSYoObU3qONesWeMcxlqnTh3z2nny5DHDnKdOnWqGa7rS7XU7Pc7y5cub9zAhnTdDT1TdRod/6twirvSX88UXXzTDZPUX49FHH3ULqeqPP/6wWrVqZeYa0S8P/VK5efNmuo/T0337+3G62r59uxk+rH/MwsLCrKpVq1qjRo1y+4Psb+dxZrP7rHxJh0wXL17clE0/F71/8OBBr59H3jinU0NfL6nfRf0dzey/id44r9NynBomNBxoKNDwotN/6JxBCUNoIBynJPNd6Xoe+dO56klZ7IT878ABAACQlfswAQAApAeBCQAAwAaBCQAAwAaBCQAAwAaBCQAAwAaBCQAAwAaBCQAAwAaBCQAAwAaBCUCWERISIgsXLvR1MQAEIAITAACADQITAHjoxo0bvi4CAB8hMAEIKN98843UrFlTwsPDpVChQtKsWTO5evWqbN26VZo3by6FCxeW/PnzywMPPCA7duxIcV+vv/66VKpUSXLnzi3ly5eXt956S27evOlcP2zYMKlTp478+9//lnLlyklYWJjMmjXLvG5sbKzbvtq3by9du3bNsOMG4FsEJgAB4+TJk9KpUyd55plnZN++fbJ27Vrp0KGD6DXEL1++LN27d5cNGzbI5s2bpWLFitK6dWvzeHLy5csnM2fOlL1798qHH34on376qYwfP95tm4MHD8q8efNk/vz5smvXLnnsscckLi5Ovv32W+c2Z86cke+//96UC0BwCrH0Lw0ABACtMapXr5788ccfUqZMmRS3jY+PlwIFCsjs2bPl4Ycfdnb6XrBggakNSsr7778vc+bMkW3btjlrmEaNGiV//fWXFClSxLndiy++aMqwePFic3/cuHEyadIkE670NQAEH2qYAASM2rVrS9OmTU2TnNb0aI3QhQsXzLrTp09Lr169TM2SNslFRETIlStX5OjRo8nu76uvvpJGjRpJZGSk5M2bVwYPHpxoew1mrmFJ6essX77cBCmltVQ9evQgLAFBjMAEIGBkz55dVqxYIUuWLJFq1arJxIkTpXLlynLkyBHTHKdNZtq0tnHjRvOz9jVKrqP2pk2bpHPnzqbZbtGiRbJz50558803E22fJ0+eRM+tW7euCW/an2n79u2yZ88eE5gABK8cvi4AAKSG1uJorZAuQ4YMMTVA2sz2448/yuTJk00AUseOHZNz584lux8NVfpcDUkOf/75p8fl+Oc//ykTJkwwtUza8bxUqVLpPDIA/ozABCBgbNmyRVatWiUtWrSQokWLmvtnz56VqlWrmqa4//znP1K/fn25dOmSDBw40IykS45ur81v2mfprrvuMp22NXh56qmnnpIBAwaYZkGtaQIQ3GiSAxAwtF/S+vXrTS2STgegfY4++OADadWqlUybNs30Z7rzzjvN8P6XX37ZhKrkPPLII9K3b1/p06ePmTpAa5x0WgFPaT+pjh07mr5PyXUiBxA8GCUHAGmkHdCrV68uH330ka+LAiCDEZgAIJW0JkvngPrHP/5h5nDSjucAght9mAAglXSUnIamMWPGEJaALIIaJgAAABt0+gYAALBBYAIAALBBYAIAALBBYAIAALBBYAIAALBBYAIAALBBYAIAALBBYAIAALBBYAIAAJCU/X/Jp/yTpSzfbQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================\n",
    "# 2) Load data\n",
    "# ==========================\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Primary expected path\n",
    "DATA_PATH = Path(\"../data/processed/cleaned_master.csv\")\n",
    "\n",
    "# Auto-fallback to processed dataset if not found\n",
    "if not DATA_PATH.exists():\n",
    "    alt_path = Path(\"data/processed/cleaned_master.csv\")\n",
    "    if alt_path.exists():\n",
    "        print(f\"⚠️ master_jobs_ready.csv not found, using fallback -> {alt_path}\")\n",
    "        DATA_PATH = alt_path\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            \"❌ Neither 'outputs/tables/master_jobs_ready.csv' nor 'data/processed/cleaned_master.csv' found.\\n\"\n",
    "            \"Please verify your data folder structure.\"\n",
    "        )\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"✅ Data loaded successfully from:\", DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head(3))\n",
    "\n",
    "# Detect target column automatically\n",
    "TARGET_CANDIDATES = [c for c in [\"salary\", \"salary_usd\", \"salary_midpoint\"] if c in df.columns]\n",
    "assert len(TARGET_CANDIDATES) > 0, \\\n",
    "    \"No salary target found. Expected one of: 'salary', 'salary_usd', 'salary_midpoint'.\"\n",
    "TARGET = TARGET_CANDIDATES[0]\n",
    "print(\"Chosen target:\", TARGET)\n",
    "\n",
    "# Summary of the target variable\n",
    "print(\"\\nTarget summary statistics:\")\n",
    "display(df[TARGET].describe(percentiles=[.1, .25, .5, .75, .9, .95, .99]))\n",
    "\n",
    "# Distribution plot of the target\n",
    "plt.figure(figsize=(6, 4))\n",
    "df[TARGET].dropna().plot(kind=\"hist\", bins=40, edgecolor=\"black\")\n",
    "plt.title(f\"Target distribution: {TARGET}\")\n",
    "plt.xlabel(TARGET)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/figures/salary_target_hist.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Target & unit normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier clip range: (-171025.96, 197570.09)\n",
      "Using log1p: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>_target_transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186597.0</td>\n",
       "      <td>12.136712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110630.0</td>\n",
       "      <td>11.613956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61280.0</td>\n",
       "      <td>11.023225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154130.0</td>\n",
       "      <td>11.945558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172312.0</td>\n",
       "      <td>12.057068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     salary  _target_transformed\n",
       "0  186597.0            12.136712\n",
       "1  110630.0            11.613956\n",
       "2   61280.0            11.023225\n",
       "3  154130.0            11.945558\n",
       "4  172312.0            12.057068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If pay period exists, normalize to annual (heuristics; adjust if columns differ)\n",
    "# Expected columns (if present): pay_period in {'hourly','daily','weekly','monthly','annual'}\n",
    "# and salary column is numeric in that period's units.\n",
    "df_norm = df.copy()\n",
    "\n",
    "pay_col = None\n",
    "for c in [\"pay_period\",\"salary_period\",\"comp_period\"]:\n",
    "    if c in df_norm.columns:\n",
    "        pay_col = c\n",
    "        break\n",
    "\n",
    "def to_annual(sal, period):\n",
    "    if pd.isna(sal): return np.nan\n",
    "    if period == \"hourly\":   return sal * 2080  # 40h * 52w\n",
    "    if period == \"daily\":    return sal * 260   # 5d * 52w\n",
    "    if period == \"weekly\":   return sal * 52\n",
    "    if period == \"monthly\":  return sal * 12\n",
    "    return sal  # assume already annual\n",
    "\n",
    "if pay_col:\n",
    "    df_norm[TARGET] = [\n",
    "        to_annual(s, p) for s, p in zip(df_norm[TARGET], df_norm[pay_col].astype(str).str.lower())\n",
    "    ]\n",
    "\n",
    "# Remove unrealistic outliers via quantile clip (1% - 99%)\n",
    "low, high = df_norm[TARGET].quantile([0.01, 0.99])\n",
    "df_norm[TARGET] = df_norm[TARGET].clip(lower=low, upper=high)\n",
    "\n",
    "# Optional: log1p transform\n",
    "USE_LOG1P = True\n",
    "if USE_LOG1P:\n",
    "    df_norm[\"_target_transformed\"] = np.log1p(df_norm[TARGET])\n",
    "    target_for_model = \"_target_transformed\"\n",
    "else:\n",
    "    target_for_model = TARGET\n",
    "\n",
    "print(\"Outlier clip range:\", (float(low), float(high)))\n",
    "print(\"Using log1p:\", USE_LOG1P)\n",
    "display(df_norm[[TARGET, target_for_model]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical: ['job_title', 'experience_level', 'employment_type', 'work_setting', 'industry']\n",
      "Numeric    : ['years_experience', 'salary_in_usd', 'salary_usd', 'remote_ratio', 'benefits_score']\n",
      "Skill cols : ['skill_python', 'skill_sql', 'skill_tensorflow', 'skill_kubernetes', 'skill_pytorch', 'skill_scala', 'skill_linux', 'skill_git', 'skill_java', 'skill_gcp', '...']\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 4) Feature preparation\n",
    "# ==========================\n",
    "import re\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# If category_encoders was imported earlier, we have HAS_CE flag; else set it safely here\n",
    "try:\n",
    "    HAS_CE\n",
    "except NameError:\n",
    "    try:\n",
    "        import category_encoders as ce\n",
    "        HAS_CE = True\n",
    "    except Exception:\n",
    "        HAS_CE = False\n",
    "\n",
    "# ---- Pick categorical & numeric feature candidates (present-only) ----\n",
    "cat_cols = [c for c in [\n",
    "    \"job_title\",\"company\",\"location\",\"country\",\"city\",\"experience_level\",\n",
    "    \"employment_type\",\"work_setting\",\"industry\",\"education_level\",\"seniority\"\n",
    "] if c in df_norm.columns]\n",
    "\n",
    "num_cols = [c for c in [\n",
    "    \"years_experience\",\"skill_demand_last_3m\",\"skill_demand_last_6m\",\"skill_demand_momentum\"\n",
    "] if c in df_norm.columns]\n",
    "\n",
    "# Add other numeric-looking columns dynamically (counts/ratios/etc.) excluding target/transformed\n",
    "for c in df_norm.columns:\n",
    "    if c not in cat_cols and c not in [TARGET, \"_target_transformed\"]:\n",
    "        if pd.api.types.is_numeric_dtype(df_norm[c]):\n",
    "            if re.search(r\"(count|score|index|ratio|rate|usd|midpoint|min|max)\", c, flags=re.I):\n",
    "                if c not in num_cols:\n",
    "                    num_cols.append(c)\n",
    "\n",
    "# ---- Skills → multi-hot (top N) if a text column exists ----\n",
    "skills_col = next((c for c in [\"skills\",\"required_skills\",\"job_skill_set\"] if c in df_norm.columns), None)\n",
    "\n",
    "TOP_N_SKILLS = 30\n",
    "skill_cols = []\n",
    "if skills_col:\n",
    "    def split_skills(x):\n",
    "        if pd.isna(x): return []\n",
    "        s = str(x).lower()\n",
    "        parts = re.split(r\"[;,|/]\", s)\n",
    "        return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "    skill_lists = df_norm[skills_col].apply(split_skills)\n",
    "\n",
    "    from collections import Counter\n",
    "    ctr = Counter()\n",
    "    for lst in skill_lists:\n",
    "        ctr.update(lst)\n",
    "\n",
    "    top_skills = [s for s,_ in ctr.most_common(TOP_N_SKILLS)]\n",
    "    for sk in top_skills:\n",
    "        safe = re.sub(r\"[^a-z0-9]+\", \"_\", sk)\n",
    "        col = f\"skill_{safe}\"\n",
    "        df_norm[col] = skill_lists.apply(lambda lst: int(sk in lst))\n",
    "        skill_cols.append(col)\n",
    "\n",
    "# ---- Imputation strategies ----\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# ---- Encoding for categorical features ----\n",
    "if HAS_CE and len(cat_cols) > 0:\n",
    "    # TargetEncoder for high-cardinality categories (requires category_encoders)\n",
    "    cat_encoder = ce.TargetEncoder(cols=cat_cols)\n",
    "    cat_pipeline = Pipeline([(\"impute\", cat_imputer), (\"encode\", cat_encoder)])\n",
    "else:\n",
    "    # OneHotEncoder fallback, compatible across sklearn versions\n",
    "    if \"sparse_output\" in inspect.signature(OneHotEncoder).parameters:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    else:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "    cat_pipeline = Pipeline([(\"impute\", cat_imputer), (\"encode\", ohe)])\n",
    "\n",
    "# ---- Numeric scaler (also handles binary skill columns) ----\n",
    "num_pipeline = Pipeline([(\"impute\", num_imputer), (\"scale\", StandardScaler())])\n",
    "\n",
    "# ---- ColumnTransformer ----\n",
    "all_features = cat_cols + num_cols + skill_cols\n",
    "print(\"Categorical:\", cat_cols)\n",
    "print(\"Numeric    :\", (num_cols[:20] + ([\"...\"] if len(num_cols) > 20 else [])))\n",
    "print(\"Skill cols :\", (skill_cols[:10] + ([\"...\"] if len(skill_cols) > 10 else [])))\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", cat_pipeline, cat_cols),\n",
    "        (\"num\", num_pipeline, num_cols + skill_cols)  # skills are numeric/binary\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# ---- Feature dictionary for manifest ----\n",
    "feature_dict = []\n",
    "for c in cat_cols:\n",
    "    feature_dict.append({\"name\": c, \"type\": \"categorical\", \"description\": \"Categorical feature\"})\n",
    "for c in (num_cols + skill_cols):\n",
    "    feature_dict.append({\"name\": c, \"type\": \"numeric\", \"description\": \"Numeric feature\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (28933, 34) Valid: (7234, 34)\n"
     ]
    }
   ],
   "source": [
    "# Time-aware split if a date exists; else random split\n",
    "date_col = None\n",
    "for c in [\"posted_date\",\"posting_date\",\"period\",\"posting_year\"]:\n",
    "    if c in df_norm.columns:\n",
    "        date_col = c\n",
    "        break\n",
    "\n",
    "if date_col and pd.api.types.is_datetime64_any_dtype(df_norm[date_col]):\n",
    "    # Sort by date, use last 20% as validation\n",
    "    df_sorted = df_norm.sort_values(date_col)\n",
    "    split_idx = int(len(df_sorted)*0.8)\n",
    "    train_df = df_sorted.iloc[:split_idx]\n",
    "    valid_df = df_sorted.iloc[split_idx:]\n",
    "else:\n",
    "    train_df, valid_df = train_test_split(df_norm, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = train_df[all_features].copy()\n",
    "y_train = train_df[target_for_model].copy()\n",
    "X_valid = valid_df[all_features].copy()\n",
    "y_valid = valid_df[target_for_model].copy()\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Valid:\", X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Baseline & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (0, 34) Valid: (4750, 34)\n",
      "Missing y in train: 0 | Missing y in valid: 0\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# REPAIR 2/3 — Robust train/valid split\n",
    "# ==========================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Try to parse any date column if present\n",
    "date_col = next((c for c in [\"posted_date\",\"posting_date\",\"period\",\"posting_year\"] if c in df_norm.columns), None)\n",
    "if date_col and not pd.api.types.is_datetime64_any_dtype(df_norm[date_col]):\n",
    "    with pd.option_context(\"mode.chained_assignment\", None):\n",
    "        try:\n",
    "            df_norm[date_col] = pd.to_datetime(df_norm[date_col], errors=\"coerce\")\n",
    "        except Exception:\n",
    "            date_col = None\n",
    "\n",
    "# Split\n",
    "if date_col and pd.api.types.is_datetime64_any_dtype(df_norm[date_col]):\n",
    "    df_sorted = df_norm.sort_values(date_col)\n",
    "    split_idx = int(len(df_sorted) * 0.8)\n",
    "    train_df = df_sorted.iloc[:split_idx].copy()\n",
    "    valid_df = df_sorted.iloc[split_idx:].copy()\n",
    "else:\n",
    "    train_df, valid_df = train_test_split(df_norm, test_size=0.2, random_state=42)\n",
    "\n",
    "# Drop rows missing the modeling target\n",
    "train_df = train_df.dropna(subset=[target_for_model]).copy()\n",
    "valid_df = valid_df.dropna(subset=[target_for_model]).copy()\n",
    "\n",
    "# Build design matrices with only known features\n",
    "X_train = train_df[all_features].copy()\n",
    "y_train = train_df[target_for_model].astype(float).to_numpy()\n",
    "X_valid = valid_df[all_features].copy()\n",
    "y_valid = valid_df[target_for_model].astype(float).to_numpy()\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Valid:\", X_valid.shape)\n",
    "print(\"Missing y in train:\", np.isnan(y_train).sum(), \"| Missing y in valid:\", np.isnan(y_valid).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54db4a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3800, 32)  Valid: (950, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaselineMedian</td>\n",
       "      <td>41240.584589</td>\n",
       "      <td>48142.395173</td>\n",
       "      <td>-0.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>42063.948029</td>\n",
       "      <td>49433.502727</td>\n",
       "      <td>-0.055897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>45576.698494</td>\n",
       "      <td>54973.287734</td>\n",
       "      <td>-0.305817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>46085.655030</td>\n",
       "      <td>56096.125078</td>\n",
       "      <td>-0.359704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model           MAE          RMSE        R2\n",
       "0  BaselineMedian  41240.584589  48142.395173 -0.001461\n",
       "1           Ridge  42063.948029  49433.502727 -0.055897\n",
       "2    XGBRegressor  45576.698494  54973.287734 -0.305817\n",
       "3    RandomForest  46085.655030  56096.125078 -0.359704"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metrics saved → C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\tables\\salary_model_metrics.csv\n",
      "🏆 Winner: BaselineMedian\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# FIXED SPLIT + RETRAIN (filters target BEFORE split; guarantees non-empty train)\n",
    "# ==========================\n",
    "import numpy as np, pandas as pd, inspect, re, sys, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- assumptions: df_norm, TARGET, target_for_model, USE_LOG1P, all_features, preprocess, TABLES_DIR exist\n",
    "try:\n",
    "    TABLES_DIR\n",
    "except NameError:\n",
    "    TABLES_DIR = Path(\"outputs/tables\"); TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "METRICS_CSV = TABLES_DIR / \"salary_model_metrics.csv\"\n",
    "\n",
    "# 1) Keep only rows with a valid modeling target\n",
    "df_model = df_norm.dropna(subset=[target_for_model]).copy()\n",
    "assert len(df_model) > 0, \"No rows with non-missing target after preprocessing.\"\n",
    "\n",
    "# 2) Time-aware split if date exists, else random — but AFTER filtering\n",
    "from sklearn.model_selection import train_test_split\n",
    "date_col = next((c for c in [\"posted_date\",\"posting_date\",\"period\",\"posting_year\"] if c in df_model.columns), None)\n",
    "if date_col and not pd.api.types.is_datetime64_any_dtype(df_model[date_col]):\n",
    "    with pd.option_context(\"mode.chained_assignment\", None):\n",
    "        df_model[date_col] = pd.to_datetime(df_model[date_col], errors=\"coerce\")\n",
    "\n",
    "def safe_time_split(df, frac=0.8):\n",
    "    df = df.sort_values(date_col)\n",
    "    split_idx = int(len(df) * frac)\n",
    "    # Guarantee at least 1 train row and 1 valid row\n",
    "    split_idx = max(1, min(split_idx, len(df) - 1))\n",
    "    return df.iloc[:split_idx].copy(), df.iloc[split_idx:].copy()\n",
    "\n",
    "if date_col and pd.api.types.is_datetime64_any_dtype(df_model[date_col]):\n",
    "    train_df, valid_df = safe_time_split(df_model, frac=0.8)\n",
    "else:\n",
    "    # Random split but guarantee non-empty both sides\n",
    "    if len(df_model) == 1:\n",
    "        # degenerate case: use same row for train and valid (not ideal but unblocks)\n",
    "        train_df = df_model.copy()\n",
    "        valid_df = df_model.copy()\n",
    "    else:\n",
    "        train_df, valid_df = train_test_split(df_model, test_size=0.2, random_state=42)\n",
    "        if len(train_df) == 0:\n",
    "            train_df, valid_df = train_test_split(df_model, test_size=0.1, random_state=42)\n",
    "\n",
    "# 3) Build matrices\n",
    "X_train = train_df[all_features].copy()\n",
    "y_train = train_df[target_for_model].astype(float).to_numpy()\n",
    "X_valid = valid_df[all_features].copy()\n",
    "y_valid = valid_df[target_for_model].astype(float).to_numpy()\n",
    "\n",
    "print(f\"Train: {X_train.shape}  Valid: {X_valid.shape}\")\n",
    "\n",
    "# 4) Train models (version-compatible RMSE)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import sklearn\n",
    "\n",
    "_HAS_SQUARED = \"squared\" in inspect.signature(mean_squared_error).parameters\n",
    "def rmse_compat(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False) if _HAS_SQUARED else np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def inv_target(arr):\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    return np.expm1(arr) if USE_LOG1P else arr\n",
    "\n",
    "def _clean(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    m = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    return y_true[m], y_pred[m]\n",
    "\n",
    "def score_pair(y_true, y_pred, name):\n",
    "    t = inv_target(y_true); p = inv_target(y_pred)\n",
    "    t, p = _clean(t, p)\n",
    "    if t.size == 0:\n",
    "        return {\"model\": name, \"MAE\": np.nan, \"RMSE\": np.nan, \"R2\": np.nan}\n",
    "    return {\"model\": name,\n",
    "            \"MAE\": mean_absolute_error(t, p),\n",
    "            \"RMSE\": rmse_compat(t, p),\n",
    "            \"R2\": r2_score(t, p)}\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# Baseline: median in model space\n",
    "median_orig = float(np.nanmedian(inv_target(y_train)))\n",
    "fill_val = np.log1p(median_orig) if USE_LOG1P else median_orig\n",
    "baseline_pred = np.full(len(y_valid), fill_val, float)\n",
    "metrics.append(score_pair(y_valid, baseline_pred, \"BaselineMedian\"))\n",
    "\n",
    "# Ridge\n",
    "ridge = Pipeline([(\"prep\", preprocess), (\"mdl\", Ridge(alpha=1.0, random_state=42))])\n",
    "ridge.fit(X_train, y_train)\n",
    "metrics.append(score_pair(y_valid, ridge.predict(X_valid), \"Ridge\"))\n",
    "\n",
    "# RandomForest\n",
    "rf = Pipeline([(\"prep\", preprocess), (\"mdl\", RandomForestRegressor(\n",
    "    n_estimators=300, random_state=42, n_jobs=-1))])\n",
    "rf.fit(X_train, y_train)\n",
    "metrics.append(score_pair(y_valid, rf.predict(X_valid), \"RandomForest\"))\n",
    "\n",
    "# XGB or HGB\n",
    "best_gbm_pipe = None\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    xgb = Pipeline([(\"prep\", preprocess), (\"mdl\", XGBRegressor(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=6,\n",
    "        subsample=0.9, colsample_bytree=0.9, random_state=42,\n",
    "        n_jobs=-1, objective=\"reg:squarederror\"))])\n",
    "    xgb.fit(X_train, y_train)\n",
    "    metrics.append(score_pair(y_valid, xgb.predict(X_valid), \"XGBRegressor\"))\n",
    "    best_gbm_pipe = xgb\n",
    "    gbm_name = \"XGBRegressor\"\n",
    "except Exception:\n",
    "    hgb = Pipeline([(\"prep\", preprocess), (\"mdl\", HistGradientBoostingRegressor(\n",
    "        learning_rate=0.08, random_state=42))])\n",
    "    hgb.fit(X_train, y_train)\n",
    "    metrics.append(score_pair(y_valid, hgb.predict(X_valid), \"HistGradientBoosting\"))\n",
    "    best_gbm_pipe = hgb\n",
    "    gbm_name = \"HistGradientBoosting\"\n",
    "\n",
    "# Metrics table & save\n",
    "metrics_df = pd.DataFrame(metrics).sort_values(\"RMSE\").reset_index(drop=True)\n",
    "display(metrics_df)\n",
    "metrics_df.to_csv(METRICS_CSV, index=False)\n",
    "print(\"✅ Metrics saved →\", METRICS_CSV)\n",
    "\n",
    "winner = metrics_df.iloc[0][\"model\"]\n",
    "best_pipeline = {\n",
    "    \"BaselineMedian\": None,\n",
    "    \"Ridge\": ridge,\n",
    "    \"RandomForest\": rf,\n",
    "    \"XGBRegressor\": best_gbm_pipe if gbm_name == \"XGBRegressor\" else None,\n",
    "    \"HistGradientBoosting\": best_gbm_pipe if gbm_name == \"HistGradientBoosting\" else None\n",
    "}[winner]\n",
    "print(\"🏆 Winner:\", winner)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Metrics & reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.9 | sklearn: 1.7.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaselineMedian</td>\n",
       "      <td>41240.584589</td>\n",
       "      <td>48142.395173</td>\n",
       "      <td>-0.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>42063.948029</td>\n",
       "      <td>49433.502727</td>\n",
       "      <td>-0.055897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>45576.698494</td>\n",
       "      <td>54973.287734</td>\n",
       "      <td>-0.305817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>46085.655030</td>\n",
       "      <td>56096.125078</td>\n",
       "      <td>-0.359704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model           MAE          RMSE        R2\n",
       "0  BaselineMedian  41240.584589  48142.395173 -0.001461\n",
       "1           Ridge  42063.948029  49433.502727 -0.055897\n",
       "3    XGBRegressor  45576.698494  54973.287734 -0.305817\n",
       "2    RandomForest  46085.655030  56096.125078 -0.359704"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metrics saved -> C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\tables\\salary_model_metrics.csv\n",
      "Best model by RMSE: BaselineMedian\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# REPAIR 3/3 — Baseline & models (version-compatible)\n",
    "# ==========================\n",
    "import numpy as np, pandas as pd, inspect, sys, sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0], \"| sklearn:\", sklearn.__version__)\n",
    "\n",
    "def inv_target(arr):\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    if USE_LOG1P:\n",
    "        return np.expm1(arr)\n",
    "    return arr\n",
    "\n",
    "def _clean_pair(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    return y_true[mask], y_pred[mask]\n",
    "\n",
    "_HAS_SQUARED = \"squared\" in inspect.signature(mean_squared_error).parameters\n",
    "def rmse_compat(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False) if _HAS_SQUARED else np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def eval_metrics(y_true, y_pred, label):\n",
    "    true = inv_target(y_true)\n",
    "    pred = inv_target(y_pred)\n",
    "    true, pred = _clean_pair(true, pred)\n",
    "    if true.size == 0:\n",
    "        return {\"model\": label, \"MAE\": np.nan, \"RMSE\": np.nan, \"R2\": np.nan}\n",
    "    return {\n",
    "        \"model\": label,\n",
    "        \"MAE\": mean_absolute_error(true, pred),\n",
    "        \"RMSE\": rmse_compat(true, pred),\n",
    "        \"R2\": r2_score(true, pred),\n",
    "    }\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# ---- Baseline: median constant in model-space ----\n",
    "median_val_orig = float(np.nanmedian(inv_target(y_train)))\n",
    "fill_val = np.log1p(median_val_orig) if USE_LOG1P else median_val_orig\n",
    "baseline_pred = np.full(shape=(len(y_valid),), fill_value=fill_val, dtype=float)\n",
    "metrics.append(eval_metrics(y_valid, baseline_pred, \"BaselineMedian\"))\n",
    "\n",
    "# ---- Ridge ----\n",
    "ridge = Pipeline([(\"prep\", preprocess), (\"mdl\", Ridge(alpha=1.0, random_state=42))])\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_pred = ridge.predict(X_valid)\n",
    "metrics.append(eval_metrics(y_valid, ridge_pred, \"Ridge\"))\n",
    "\n",
    "# ---- RandomForest ----\n",
    "rf = Pipeline([(\"prep\", preprocess), (\"mdl\", RandomForestRegressor(\n",
    "    n_estimators=300, max_depth=None, random_state=42, n_jobs=-1))])\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_valid)\n",
    "metrics.append(eval_metrics(y_valid, rf_pred, \"RandomForest\"))\n",
    "\n",
    "# ---- GBM: XGB if available else HistGB ----\n",
    "best_gbm_name, best_gbm_pipe = None, None\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    xgb = Pipeline([(\"prep\", preprocess), (\"mdl\", XGBRegressor(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=6, subsample=0.9,\n",
    "        colsample_bytree=0.9, random_state=42, n_jobs=-1, objective=\"reg:squarederror\"))])\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pred = xgb.predict(X_valid)\n",
    "    metrics.append(eval_metrics(y_valid, xgb_pred, \"XGBRegressor\"))\n",
    "    best_gbm_name, best_gbm_pipe = \"XGBRegressor\", xgb\n",
    "except Exception:\n",
    "    hgb = Pipeline([(\"prep\", preprocess), (\"mdl\", HistGradientBoostingRegressor(\n",
    "        learning_rate=0.08, max_depth=None, random_state=42))])\n",
    "    hgb.fit(X_train, y_train)\n",
    "    hgb_pred = hgb.predict(X_valid)\n",
    "    metrics.append(eval_metrics(y_valid, hgb_pred, \"HistGradientBoosting\"))\n",
    "    best_gbm_name, best_gbm_pipe = \"HistGradientBoosting\", hgb\n",
    "\n",
    "# ---- Metrics table & winner ----\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "display(metrics_df.sort_values(\"RMSE\"))\n",
    "\n",
    "metrics_df.to_csv(METRICS_CSV, index=False)\n",
    "print(\"✅ Metrics saved ->\", METRICS_CSV)\n",
    "\n",
    "idx = metrics_df[\"RMSE\"].idxmin()\n",
    "best_row = metrics_df.loc[idx]\n",
    "best_name = best_row[\"model\"]\n",
    "print(\"Best model by RMSE:\", best_name)\n",
    "\n",
    "best_pipeline = {\n",
    "    \"BaselineMedian\": None,\n",
    "    \"Ridge\": ridge,\n",
    "    \"RandomForest\": rf,\n",
    "    \"XGBRegressor\": best_gbm_pipe if best_gbm_name == \"XGBRegressor\" else None,\n",
    "    \"HistGradientBoosting\": best_gbm_pipe if best_gbm_name == \"HistGradientBoosting\" else None\n",
    "}[best_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Feature importance / explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_importances(model_pipeline, topn=20, title=\"Feature Importance\"):\n",
    "    # Extract feature names post-transform\n",
    "    prep = model_pipeline.named_steps[\"prep\"]\n",
    "    cat_cols = prep.transformers_[0][2]\n",
    "    num_cols = prep.transformers_[1][2]\n",
    "    # Handle OneHot\n",
    "    cat_enc = prep.named_transformers_[\"cat\"].named_steps.get(\"encode\", None)\n",
    "    if cat_enc is not None and hasattr(cat_enc, \"get_feature_names_out\"):\n",
    "        cat_names = list(cat_enc.get_feature_names_out(cat_cols))\n",
    "    else:\n",
    "        cat_names = list(cat_cols)\n",
    "    feat_names = cat_names + list(num_cols)\n",
    "\n",
    "    mdl = model_pipeline.named_steps[\"mdl\"]\n",
    "    importances = None\n",
    "    if hasattr(mdl, \"feature_importances_\"):\n",
    "        importances = mdl.feature_importances_\n",
    "    elif hasattr(mdl, \"coef_\"):\n",
    "        coefs = mdl.coef_.ravel() if hasattr(mdl.coef_, \"ravel\") else mdl.coef_\n",
    "        importances = np.abs(coefs)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    imp_df = pd.DataFrame({\"feature\": feat_names, \"importance\": importances})\n",
    "    imp_df = imp_df.sort_values(\"importance\", ascending=False).head(topn)\n",
    "\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.barh(imp_df[\"feature\"][::-1], imp_df[\"importance\"][::-1])\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / \"salary_feature_importance.png\", dpi=150)\n",
    "    plt.show()\n",
    "    return imp_df\n",
    "\n",
    "if best_pipeline is not None:\n",
    "    imp_table = plot_top_importances(best_pipeline, title=f\"Feature Importance — {best_name}\")\n",
    "    if imp_table is not None:\n",
    "        display(imp_table)\n",
    "\n",
    "# Optional: SHAP for tree/boosting models\n",
    "if HAS_SHAP and best_pipeline is not None:\n",
    "    try:\n",
    "        prepared = best_pipeline.named_steps[\"prep\"].fit_transform(X_train, y_train)\n",
    "        mdl = best_pipeline.named_steps[\"mdl\"]\n",
    "        # TreeExplainer preferred for tree-based; else KernelExplainer (expensive)\n",
    "        if hasattr(mdl, \"predict\") and (hasattr(mdl, \"feature_importances_\") or \"XGB\" in best_name or \"HistGradient\" in best_name or \"RandomForest\" in best_name):\n",
    "            explainer = shap.Explainer(mdl, prepared, feature_names=None)\n",
    "            shap_vals = explainer(prepared[:200])  # subsample for speed\n",
    "            shap.plots.bars(shap_vals, show=True, max_display=20)\n",
    "            plt.gcf().savefig(FIG_DIR / \"salary_shap_summary.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    except Exception as e:\n",
    "        print(\"SHAP skipped due to error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Save artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved baseline metadata -> C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\models\\salary_predictor.json\n",
      "✅ Saved features manifest -> C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\models\\salary_features.json\n"
     ]
    }
   ],
   "source": [
    "import joblib, time\n",
    "\n",
    "if best_pipeline is not None:\n",
    "    joblib.dump(best_pipeline, MODEL_PATH)\n",
    "    print(\"✅ Saved best pipeline ->\", MODEL_PATH)\n",
    "else:\n",
    "    # Save median baseline as dict metadata\n",
    "    with open(MODEL_PATH.with_suffix(\".json\"), \"w\") as f:\n",
    "        json.dump({\"type\":\"median_baseline\",\"median\": median_val}, f, indent=2)\n",
    "    print(\"Saved baseline metadata ->\", MODEL_PATH.with_suffix(\".json\"))\n",
    "\n",
    "manifest = {\n",
    "    \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"target\": TARGET,\n",
    "    \"log1p\": bool(USE_LOG1P),\n",
    "    \"feature_spec\": feature_dict,\n",
    "    \"skills_top_n\": int(30),\n",
    "    \"preprocessing\": \"TargetEncoder\" if \"TargetEncoder\" in str(preprocess) else \"OneHot + StandardScaler\",\n",
    "    \"train_rows\": int(len(X_train)),\n",
    "    \"valid_rows\": int(len(X_valid)),\n",
    "    \"models_evaluated\": metrics_df[\"model\"].tolist(),\n",
    "    \"winner\": best_name\n",
    "}\n",
    "with open(FEATURES_MANIFEST, \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "print(\"✅ Saved features manifest ->\", FEATURES_MANIFEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Inference demo cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple predict function that loads the saved pipeline and predicts on a one-row dict\n",
    "def predict_salary(sample: dict, model_path=MODEL_PATH):\n",
    "    import pandas as pd, numpy as np, joblib, json\n",
    "    if model_path.exists() and model_path.suffix == \".pkl\":\n",
    "        pipe = joblib.load(model_path)\n",
    "        df = pd.DataFrame([sample])\n",
    "        # Ensure missing expected columns exist\n",
    "        expected = []\n",
    "        prep = pipe.named_steps.get(\"prep\")\n",
    "        if prep is not None:\n",
    "            expected = list(prep.get_feature_names_out()) if hasattr(prep, \"get_feature_names_out\") else None\n",
    "        yhat = pipe.predict(df)[0]\n",
    "        return float(np.expm1(yhat)) if bool({True}) else float(yhat)\n",
    "    else:\n",
    "        # median baseline fallback (if only JSON saved)\n",
    "        meta_json = model_path.with_suffix(\".json\")\n",
    "        if meta_json.exists():\n",
    "            meta = json.load(open(meta_json))\n",
    "            return float(meta[\"median\"])\n",
    "        raise FileNotFoundError(\"Model artifact not found.\")\n",
    "\n",
    "# Example(s) — EDIT with your schema/values\n",
    "example_1 = {\n",
    "    \"job_title\": \"Data Scientist\",\n",
    "    \"country\": \"United States\",\n",
    "    \"experience_level\": \"Senior\",\n",
    "    \"employment_type\": \"FT\",\n",
    "    \"work_setting\": \"remote\",\n",
    "    \"industry\": \"Technology\",\n",
    "    \"education_level\": \"Bachelors\",\n",
    "    \"years_experience\": 6,\n",
    "    \"skills\": \"python;sql;machine learning;aws\"\n",
    "}\n",
    "# predict_salary(example_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Repro & summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner: BaselineMedian\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaselineMedian</td>\n",
       "      <td>41240.584589</td>\n",
       "      <td>48142.395173</td>\n",
       "      <td>-0.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>42063.948029</td>\n",
       "      <td>49433.502727</td>\n",
       "      <td>-0.055897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>46085.655030</td>\n",
       "      <td>56096.125078</td>\n",
       "      <td>-0.359704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>45576.698494</td>\n",
       "      <td>54973.287734</td>\n",
       "      <td>-0.305817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model           MAE          RMSE        R2\n",
       "0  BaselineMedian  41240.584589  48142.395173 -0.001461\n",
       "1           Ridge  42063.948029  49433.502727 -0.055897\n",
       "2    RandomForest  46085.655030  56096.125078 -0.359704\n",
       "3    XGBRegressor  45576.698494  54973.287734 -0.305817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Artifacts saved:\n",
      "- C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\tables\\salary_model_metrics.csv\n",
      "- C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\models\\salary_predictor.json\n",
      "- C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\models\\salary_features.json\n",
      "- C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\figures\\salary_model_mae.png\n",
      "- C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\figures\\salary_model_rmse.png\n",
      "- C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\outputs\\figures\\salary_actual_vs_pred.png\n",
      "\n",
      "Limitations & next steps:\n",
      "* Features may not capture benefits/equity; regional variance not fully normalized.\n",
      "* If skills text is noisy, taxonomy mapping could improve signal.\n",
      "* Consider modeling by experience bands and adding cost-of-living indices.\n",
      "* Try permutation importance, partial dependence, and calibrated prediction intervals.\n"
     ]
    }
   ],
   "source": [
    "print(\"Winner:\", best_name)\n",
    "display(metrics_df)\n",
    "\n",
    "print(\"\\nArtifacts saved:\")\n",
    "print(\"-\", METRICS_CSV)\n",
    "print(\"-\", MODEL_PATH if MODEL_PATH.exists() else MODEL_PATH.with_suffix(\".json\"))\n",
    "print(\"-\", FEATURES_MANIFEST)\n",
    "print(\"-\", FIG_DIR / \"salary_model_mae.png\")\n",
    "print(\"-\", FIG_DIR / \"salary_model_rmse.png\")\n",
    "print(\"-\", FIG_DIR / \"salary_actual_vs_pred.png\")\n",
    "\n",
    "print(\"\\nLimitations & next steps:\")\n",
    "print(\"* Features may not capture benefits/equity; regional variance not fully normalized.\")\n",
    "print(\"* If skills text is noisy, taxonomy mapping could improve signal.\")\n",
    "print(\"* Consider modeling by experience bands and adding cost-of-living indices.\")\n",
    "print(\"* Try permutation importance, partial dependence, and calibrated prediction intervals.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
