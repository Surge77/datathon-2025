{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53faa7fa",
   "metadata": {},
   "source": [
    "\n",
    "# 04 — Feature Engineering (Phase 4)\n",
    "\n",
    "**Goal:** Transform `cleaned_master.csv` into modeling‑ready features for salary prediction, forecasting, clustering, and recommendations.\n",
    "\n",
    "**Inputs**\n",
    "- `data/processed/cleaned_master.csv` (or fallback: uploaded `cleaned_master.csv`)\n",
    "\n",
    "**Outputs**\n",
    "- `data/processed/X_train.csv`, `X_test.csv`, `y_train.csv`, `y_test.csv`\n",
    "- `feature_columns.json` (ordered list of feature names used in X)\n",
    "- `skill_vocab.json` (frozen list of skills encoded)\n",
    "- `preprocessing_config.json` (parameters for reproducibility)\n",
    "\n",
    "**Covers**\n",
    "- Temporal features (`posting_year`, `posting_month`, etc.)\n",
    "- Skill features (tokenization, multi‑label one‑hot for top‑K skills)\n",
    "- Salary features (`salary_midpoint`, `log_salary_midpoint`, IQR capping)\n",
    "- Categorical encodings (frequency / limited one‑hot)\n",
    "- Geographic & work setting features\n",
    "- Train/test split for downstream notebooks\n",
    "\n",
    "> Re-run this notebook whenever you update the cleaned dataset; it will regenerate features and artifacts deterministically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff3f4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pandas numpy matplotlib seaborn scikit-learn xgboost prophet shap plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0bc9b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root  : C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\n",
      "Processed  : C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\data\\processed\n",
      "Sandbox    : \\mnt\\data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Time: O(n * (k + f)); Space: O(n * (k + f))\n",
    "# n = rows, k = top-K skills, f = number of final feature columns\n",
    "from __future__ import annotations\n",
    "\n",
    "import ast\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths (edit REPO_ROOT if running outside repo)\n",
    "REPO_ROOT = Path('..').resolve()\n",
    "DATA_PROCESSED = REPO_ROOT / 'data' / 'processed'\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# In this environment we also save to /mnt/data for quick download\n",
    "SANDBOX = Path('/mnt/data')\n",
    "SANDBOX.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INPUT_CANDIDATES = [\n",
    "    DATA_PROCESSED / 'cleaned_master.csv',\n",
    "    SANDBOX / 'cleaned_master.csv',  # uploaded file fallback\n",
    "]\n",
    "\n",
    "DQ_REPORT_CANDIDATES = [\n",
    "    REPO_ROOT / 'reports' / 'data_quality_report.json',\n",
    "    SANDBOX / 'data_quality_report.json'\n",
    "]\n",
    "\n",
    "print('Repo root  :', REPO_ROOT)\n",
    "print('Processed  :', DATA_PROCESSED)\n",
    "print('Sandbox    :', SANDBOX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff66ed08",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbbf8931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cleaned dataset : C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\data\\processed\\cleaned_master.csv\n",
      "Using DQ report       : C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\reports\\data_quality_report.json\n",
      "Shape: (36167, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tdmne\\AppData\\Local\\Temp\\ipykernel_19756\\1451247071.py:17: DtypeWarning: Columns (2,9,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  master = pd.read_csv(INPUT_PATH)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_category</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>work_setting</th>\n",
       "      <th>...</th>\n",
       "      <th>required_skills</th>\n",
       "      <th>education_required</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>industry</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>application_deadline</th>\n",
       "      <th>job_description_length</th>\n",
       "      <th>benefits_score</th>\n",
       "      <th>company_name</th>\n",
       "      <th>salary_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>Machine Learning Engineer  in office</td>\n",
       "      <td>Analysis</td>\n",
       "      <td>EUR</td>\n",
       "      <td>186597.0</td>\n",
       "      <td>136086.0</td>\n",
       "      <td>US</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>Remote</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>Statistician  (Remote)</td>\n",
       "      <td>ML/AI</td>\n",
       "      <td>JPY</td>\n",
       "      <td>110630.0</td>\n",
       "      <td>67982.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>EX</td>\n",
       "      <td>FL</td>\n",
       "      <td>Remote</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>ML/AI</td>\n",
       "      <td>INR</td>\n",
       "      <td>61280.0</td>\n",
       "      <td>153309.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year                             job_title job_category  \\\n",
       "0     2022.0  Machine Learning Engineer  in office     Analysis   \n",
       "1     2020.0                Statistician  (Remote)        ML/AI   \n",
       "2     2022.0           Machine Learning Engineer          ML/AI   \n",
       "\n",
       "  salary_currency    salary  salary_in_usd employee_residence  \\\n",
       "0             EUR  186597.0       136086.0                 US   \n",
       "1             JPY  110630.0        67982.0                 JP   \n",
       "2             INR   61280.0       153309.0                 UK   \n",
       "\n",
       "  experience_level employment_type work_setting  ... required_skills  \\\n",
       "0               MI              CT       Remote  ...             NaN   \n",
       "1               EX              FL       Remote  ...             NaN   \n",
       "2               MI              CT       Hybrid  ...             NaN   \n",
       "\n",
       "  education_required years_experience industry posting_date  \\\n",
       "0                NaN              NaN      NaN          NaN   \n",
       "1                NaN              NaN      NaN          NaN   \n",
       "2                NaN              NaN      NaN          NaN   \n",
       "\n",
       "  application_deadline job_description_length  benefits_score  company_name  \\\n",
       "0                  NaN                    NaN             NaN           NaN   \n",
       "1                  NaN                    NaN             NaN           NaN   \n",
       "2                  NaN                    NaN             NaN           NaN   \n",
       "\n",
       "  salary_local  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def find_first_existing(paths):\n",
    "    for p in paths:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "INPUT_PATH = find_first_existing(INPUT_CANDIDATES)\n",
    "if INPUT_PATH is None:\n",
    "    raise FileNotFoundError('Could not find cleaned_master.csv in expected locations.')\n",
    "\n",
    "DQ_PATH = find_first_existing(DQ_REPORT_CANDIDATES)\n",
    "\n",
    "print('Using cleaned dataset :', INPUT_PATH)\n",
    "if DQ_PATH:\n",
    "    print('Using DQ report       :', DQ_PATH)\n",
    "\n",
    "master = pd.read_csv(INPUT_PATH)\n",
    "print('Shape:', master.shape)\n",
    "master.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c52b0b",
   "metadata": {},
   "source": [
    "## Inspect schema & basic hygiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120a8c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['work_year', 'job_title', 'job_category', 'salary_currency', 'salary', 'salary_in_usd', 'employee_residence', 'experience_level', 'employment_type', 'work_setting', 'company_location', 'company_size', '__source__', 'job_id', 'category', 'job_description', 'job_skill_set', 'salary_usd', 'remote_ratio', 'required_skills', 'education_required', 'years_experience', 'industry', 'posting_date', 'application_deadline', 'job_description_length', 'benefits_score', 'company_name', 'salary_local']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_category</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>work_setting</th>\n",
       "      <th>...</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>application_deadline</th>\n",
       "      <th>job_description_length</th>\n",
       "      <th>benefits_score</th>\n",
       "      <th>company_name</th>\n",
       "      <th>salary_local</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>salary_midpoint</th>\n",
       "      <th>skill_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>Machine Learning Engineer in office</td>\n",
       "      <td>Analysis</td>\n",
       "      <td>EUR</td>\n",
       "      <td>186597.0</td>\n",
       "      <td>136086.0</td>\n",
       "      <td>US</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>Remote</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>Statistician (Remote)</td>\n",
       "      <td>ML/AI</td>\n",
       "      <td>JPY</td>\n",
       "      <td>110630.0</td>\n",
       "      <td>67982.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>EX</td>\n",
       "      <td>FL</td>\n",
       "      <td>Remote</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>ML/AI</td>\n",
       "      <td>INR</td>\n",
       "      <td>61280.0</td>\n",
       "      <td>153309.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year                            job_title job_category  \\\n",
       "0     2022.0  Machine Learning Engineer in office     Analysis   \n",
       "1     2020.0                Statistician (Remote)        ML/AI   \n",
       "2     2022.0            Machine Learning Engineer        ML/AI   \n",
       "\n",
       "  salary_currency    salary  salary_in_usd employee_residence  \\\n",
       "0             EUR  186597.0       136086.0                 US   \n",
       "1             JPY  110630.0        67982.0                 JP   \n",
       "2             INR   61280.0       153309.0                 UK   \n",
       "\n",
       "  experience_level employment_type work_setting  ... posting_date  \\\n",
       "0               MI              CT       Remote  ...          NaT   \n",
       "1               EX              FL       Remote  ...          NaT   \n",
       "2               MI              CT       Hybrid  ...          NaT   \n",
       "\n",
       "  application_deadline job_description_length benefits_score company_name  \\\n",
       "0                  NaN                    NaN            NaN          NaN   \n",
       "1                  NaN                    NaN            NaN          NaN   \n",
       "2                  NaN                    NaN            NaN          NaN   \n",
       "\n",
       "  salary_local salary_min  salary_max  salary_midpoint skill_count  \n",
       "0          NaN        NaN         NaN              NaN         NaN  \n",
       "1          NaN        NaN         NaN              NaN         NaN  \n",
       "2          NaN        NaN         NaN              NaN         NaN  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "master_columns = list(master.columns)\n",
    "print('Columns:', master_columns)\n",
    "\n",
    "# Ensure expected columns exist (create if missing)\n",
    "def ensure_col(df: pd.DataFrame, name: str, default=np.nan):\n",
    "    if name not in df.columns:\n",
    "        df[name] = default\n",
    "\n",
    "expected_cols = [\n",
    "    'posting_date','required_skills','job_description','job_title','job_category',\n",
    "    'experience_level','employment_type','company_size','company_location','employee_residence',\n",
    "    'remote_ratio','salary_min','salary_max','salary_usd','salary_midpoint','skill_count'\n",
    "]\n",
    "for c in expected_cols:\n",
    "    ensure_col(master, c)\n",
    "\n",
    "# Parse dates if present\n",
    "if pd.api.types.is_object_dtype(master['posting_date']):\n",
    "    master['posting_date'] = pd.to_datetime(master['posting_date'], errors='coerce')\n",
    "\n",
    "# Normalize text-ish columns lightly\n",
    "def normalize_text(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    s = str(s).strip()\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    return s\n",
    "\n",
    "for c in ['job_title','job_category','company_size','company_location','employee_residence','experience_level','employment_type']:\n",
    "    master[c] = master[c].apply(normalize_text)\n",
    "\n",
    "master.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1561d26e",
   "metadata": {},
   "source": [
    "## Read data_quality_report.json (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61da8a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rows\": 36167,\n",
      "  \"cols\": 36,\n",
      "  \"duplicates\": 0,\n",
      "  \"completeness\": {\n",
      "    \"work_year\": 0.1382,\n",
      "    \"job_title\": 1.0,\n",
      "    \"job_category\": 0.1244,\n",
      "    \"salary_currency\": 0.9539,\n",
      "    \"salary\": 0.1382,\n",
      "    \"salary_in_usd\": 0.1382,\n",
      "    \"employee_residence\": 0.9677,\n",
      "    \"experience_level\": 0.9539,\n",
      "    \"employment_type\": 0.9677,\n",
      "    \"work_setting\": 0.1382,\n",
      "    \"company_location\": 0.9677,\n",
      "    \"company_size\": 0.9539,\n",
      "    \"__source__\": 1.0,\n",
      "    \"salary_min\": 0.0,\n",
      "    \"salary_max\": 0.0,\n",
      "    \"salary_usd\": 0.8295,\n",
      "    \"remote_ratio\": 0.8295,\n",
      "    \"posting_date\": 0.8295,\n",
      "    \"required_skills\": 0.8295,\n",
      "    \"years_experience\": 0.8295,\n",
      "    \"industry\": 0.8295,\n",
      "    \"application_deadline\": 0.8295,\n",
      "    \"job_description\": 0.0323,\n",
      "    \"company_name\": 0.8295,\n",
      "    \"job_id\": 0.8618,\n",
      "    \"category\": 0.0323,\n",
      "    \"job_skill_set\": 0.0323,\n",
      "    \"education_required\": 0.8295,\n",
      "    \"job_description_length\": 0.8295,\n",
      "    \"benefits_score\": 0.8295,\n",
      "    \"salary_local\": 0.4147,\n",
      "    \"salary_midpoint\": 0.8295,\n",
      "    \"skill_count\"...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dq = {}\n",
    "if DQ_PATH and DQ_PATH.exists():\n",
    "    try:\n",
    "        dq = json.loads(Path(DQ_PATH).read_text())\n",
    "    except Exception as e:\n",
    "        print('Failed reading DQ report:', e)\n",
    "\n",
    "print(json.dumps(dq, indent=2)[:1000] + ('...' if dq else ''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358405e9",
   "metadata": {},
   "source": [
    "## Target engineering: salary_midpoint → log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb29e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       salary_midpoint  salary_midpoint_capped  log_salary_midpoint\n",
      "count     30000.000000            30000.000000         30000.000000\n",
      "mean     118670.451700           117610.103133            11.549797\n",
      "std       62229.977054            59094.547731             0.509465\n",
      "min       16621.000000            16621.000000             9.718482\n",
      "25%       72575.750000            72575.750000            11.192400\n",
      "50%      103206.500000           103206.500000            11.544497\n",
      "75%      150921.750000           150921.750000            11.924523\n",
      "max      410273.000000           268440.750000            12.500389\n",
      "non-null targets: 30000\n"
     ]
    }
   ],
   "source": [
    "# --- Robust target construction for salary_midpoint ---\n",
    "\n",
    "def to_num(x):\n",
    "    if pd.isna(x): \n",
    "        return np.nan\n",
    "    s = str(x)\n",
    "    # strip currency, commas, and spaces\n",
    "    s = re.sub(r'[^\\d.\\-eE]', '', s)\n",
    "    try:\n",
    "        v = float(s)\n",
    "        return v if np.isfinite(v) else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# choose source columns gracefully\n",
    "has_mid = 'salary_midpoint' in master\n",
    "has_usd = 'salary_usd' in master or 'salary_in_usd' in master\n",
    "has_minmax = 'salary_min' in master and 'salary_max' in master\n",
    "\n",
    "if not has_mid:\n",
    "    master['salary_midpoint'] = np.nan\n",
    "\n",
    "# build midpoint in priority order: existing → min/max → *_in_usd/usd\n",
    "if master['salary_midpoint'].isna().all():\n",
    "    if has_minmax:\n",
    "        smin = master['salary_min'].apply(to_num)\n",
    "        smax = master['salary_max'].apply(to_num)\n",
    "        mid = (smin + smax) / 2.0\n",
    "        master['salary_midpoint'] = mid\n",
    "    if master['salary_midpoint'].isna().all() and has_usd:\n",
    "        usd_col = 'salary_usd' if 'salary_usd' in master else 'salary_in_usd'\n",
    "        master['salary_midpoint'] = master[usd_col].apply(to_num)\n",
    "\n",
    "# filter invalids\n",
    "master.loc[~np.isfinite(master['salary_midpoint']) | (master['salary_midpoint'] <= 0), 'salary_midpoint'] = np.nan\n",
    "\n",
    "# if still empty, stop early with a helpful error\n",
    "if master['salary_midpoint'].dropna().empty:\n",
    "    raise ValueError(\n",
    "        \"No usable salary values found. \"\n",
    "        \"Check that at least one of ['salary_midpoint', 'salary_min'+'salary_max', 'salary_usd'/'salary_in_usd'] \"\n",
    "        \"exists with numeric/parsible values (remove currency symbols/commas in cleaning).\"\n",
    "    )\n",
    "\n",
    "# winsorize (cap) with IQR\n",
    "def iqr_cap(series: pd.Series, k: float = 1.5):\n",
    "    q1, q3 = series.quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - k * iqr\n",
    "    upper = q3 + k * iqr\n",
    "    return series.clip(lower, upper)\n",
    "\n",
    "cap = iqr_cap(master['salary_midpoint'].dropna())\n",
    "master['salary_midpoint_capped'] = cap.reindex(master.index)\n",
    "\n",
    "# log1p target\n",
    "master['log_salary_midpoint'] = np.log1p(master['salary_midpoint_capped'])\n",
    "\n",
    "print(master[['salary_midpoint','salary_midpoint_capped','log_salary_midpoint']].describe())\n",
    "print(\"non-null targets:\", master['log_salary_midpoint'].notna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d3e1ee",
   "metadata": {},
   "source": [
    "## Temporal features from `posting_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4353e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parsed % valid dates: 82.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_year</th>\n",
       "      <th>posting_month</th>\n",
       "      <th>posting_quarter</th>\n",
       "      <th>posting_dayofweek</th>\n",
       "      <th>days_since_posting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   posting_year  posting_month  posting_quarter  posting_dayofweek  \\\n",
       "0           NaN            NaN              NaN                NaN   \n",
       "1           NaN            NaN              NaN                NaN   \n",
       "2           NaN            NaN              NaN                NaN   \n",
       "3           NaN            NaN              NaN                NaN   \n",
       "4           NaN            NaN              NaN                NaN   \n",
       "\n",
       "   days_since_posting  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Compact & reliable temporal feature builder ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Parse posting_date column robustly\n",
    "if 'posting_date' in master.columns:\n",
    "    # Try ISO / standard formats first\n",
    "    dt = pd.to_datetime(master['posting_date'], errors='coerce')\n",
    "    \n",
    "    # If many NaT (>50%), try day-first formats\n",
    "    if dt.isna().mean() > 0.5:\n",
    "        dt_alt = pd.to_datetime(master['posting_date'], errors='coerce', dayfirst=True)\n",
    "        if dt_alt.notna().sum() > dt.notna().sum():\n",
    "            dt = dt_alt\n",
    "else:\n",
    "    master['posting_date'] = np.nan\n",
    "    dt = pd.Series(pd.NaT, index=master.index)\n",
    "\n",
    "# Build simple temporal features\n",
    "master['posting_year']       = dt.dt.year\n",
    "master['posting_month']      = dt.dt.month\n",
    "master['posting_quarter']    = dt.dt.quarter\n",
    "master['posting_dayofweek']  = dt.dt.dayofweek\n",
    "master['days_since_posting'] = (pd.Timestamp.today().normalize() - dt.dt.normalize()).dt.days\n",
    "\n",
    "print(\"✅ Parsed % valid dates:\", round(100 * dt.notna().mean(), 2))\n",
    "master[['posting_year','posting_month','posting_quarter','posting_dayofweek','days_since_posting']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb49545",
   "metadata": {},
   "source": [
    "## Work setting / remote features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46b26b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['remote_hybrid', 'remote_onsite', 'remote_remote'],\n",
       " {'remote': 16121, 'onsite': 10050, 'hybrid': 9996})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remote ratio buckets: 0, 50, 100 or NaN → categorical\n",
    "def bucket_remote(r):\n",
    "    try:\n",
    "        r = float(r)\n",
    "    except Exception:\n",
    "        return 'unknown'\n",
    "    if r <= 0: return 'onsite'\n",
    "    if r < 100: return 'hybrid'\n",
    "    return 'remote'\n",
    "\n",
    "master['remote_bucket'] = master['remote_ratio'].apply(bucket_remote)\n",
    "\n",
    "# Simple one-hot for remote bucket\n",
    "remote_ohe = pd.get_dummies(master['remote_bucket'], prefix='remote')\n",
    "master = pd.concat([master, remote_ohe], axis=1)\n",
    "\n",
    "remote_ohe.columns.tolist()[:5], master['remote_bucket'].value_counts(dropna=False).to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a67b07",
   "metadata": {},
   "source": [
    "## Experience level → ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd47dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_level</th>\n",
       "      <th>experience_level_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MI</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EX</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MI</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SE</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MI</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MI</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EX</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EX</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_level  experience_level_ord\n",
       "0               MI                   2.0\n",
       "1               EX                   4.0\n",
       "2               MI                   2.0\n",
       "3               SE                   3.0\n",
       "4               MI                   2.0\n",
       "5               MI                   2.0\n",
       "6               EX                   4.0\n",
       "7               EX                   4.0\n",
       "8              NaN                   NaN\n",
       "9               EN                   1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle-style experience levels: IN, EN, MI, SE, EX\n",
    "exp_map = {\n",
    "    'IN': 0,   # Intern\n",
    "    'EN': 1,   # Entry-level / Junior\n",
    "    'MI': 2,   # Mid-level\n",
    "    'SE': 3,   # Senior\n",
    "    'EX': 4    # Executive\n",
    "}\n",
    "\n",
    "def map_exp(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip().upper()\n",
    "    return exp_map.get(s, np.nan)\n",
    "\n",
    "master['experience_level_ord'] = master['experience_level'].apply(map_exp)\n",
    "master[['experience_level','experience_level_ord']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0216a30b",
   "metadata": {},
   "source": [
    "## Frequency encoding: location, company_size, job_title (top‑limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad3f7351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,\n",
       " ['Machine Learning Engineer',\n",
       "  'Data Engineer',\n",
       "  'Data Scientist',\n",
       "  'Data Analyst',\n",
       "  'Machine Learning Researcher',\n",
       "  'Autonomous Systems Engineer',\n",
       "  'AI Architect',\n",
       "  'Robotics Engineer',\n",
       "  'AI Software Engineer',\n",
       "  'AI Product Manager'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def freq_encode(series: pd.Series) -> pd.Series:\n",
    "    freq = series.value_counts(dropna=True)\n",
    "    return series.map(freq).fillna(0).astype(float)\n",
    "\n",
    "master['loc_freq'] = freq_encode(master['company_location'].astype(str))\n",
    "master['company_size_freq'] = freq_encode(master['company_size'].astype(str))\n",
    "\n",
    "# For very high‑cardinality job titles, keep top N as one‑hot, rest → 'other'\n",
    "TOP_TITLES = 30\n",
    "top_titles = master['job_title'].value_counts().head(TOP_TITLES).index.tolist()\n",
    "master['job_title_limited'] = master['job_title'].where(master['job_title'].isin(top_titles), other='other')\n",
    "job_ohe = pd.get_dummies(master['job_title_limited'], prefix='title')\n",
    "master = pd.concat([master, job_ohe], axis=1)\n",
    "\n",
    "len(top_titles), top_titles[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef49759",
   "metadata": {},
   "source": [
    "## Skill features (multi‑label one‑hot for top‑K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d79f4b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top skills kept: 24\n",
      "['python', 'sql', 'tensorflow', 'kubernetes', 'pytorch', 'scala', 'linux', 'git', 'java', 'gcp', 'hadoop', 'r', 'tableau', 'computer vision', 'data visualization', 'spark', 'mlops', 'azure', 'deep learning', 'nlp']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_skills(val) -> List[str]:\n",
    "    if pd.isna(val): return []\n",
    "    s = str(val).strip()\n",
    "    # Handle list-like strings: \"['Python', 'SQL']\" OR comma separated \"Python, SQL\"\n",
    "    if s.startswith('[') and s.endswith(']'):\n",
    "        try:\n",
    "            lst = ast.literal_eval(s)\n",
    "            return [str(x).strip().lower() for x in lst if str(x).strip()]\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Fallback: comma‑separated\n",
    "    return [t.strip().lower() for t in s.split(',') if t.strip()]\n",
    "\n",
    "skill_lists = master['required_skills'].apply(parse_skills)\n",
    "skill_freq = {}\n",
    "for lst in skill_lists:\n",
    "    for sk in lst:\n",
    "        skill_freq[sk] = skill_freq.get(sk, 0) + 1\n",
    "\n",
    "# Keep top‑K skills to avoid huge matrices\n",
    "TOP_K_SKILLS = 100\n",
    "top_skills = [s for s, _ in sorted(skill_freq.items(), key=lambda x: x[1], reverse=True)[:TOP_K_SKILLS]]\n",
    "\n",
    "def filter_to_top(lst: List[str]) -> List[str]:\n",
    "    return [s for s in lst if s in top_skills]\n",
    "\n",
    "filtered_skill_lists = skill_lists.apply(filter_to_top)\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=top_skills)\n",
    "skill_ohe = pd.DataFrame(mlb.fit_transform(filtered_skill_lists),\n",
    "                         columns=[f\"skill__{s}\" for s in mlb.classes_],\n",
    "                         index=master.index)\n",
    "\n",
    "master = pd.concat([master, skill_ohe], axis=1)\n",
    "\n",
    "print('Top skills kept:', len(top_skills))\n",
    "print(top_skills[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04225f",
   "metadata": {},
   "source": [
    "## Assemble final feature matrix `X` and targets `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23fd7a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (30000, 68) | y shape: (30000,)\n",
      "Feature sample: ['experience_level_ord', 'loc_freq', 'company_size_freq', 'posting_year', 'posting_month', 'posting_quarter', 'posting_dayofweek', 'days_since_posting', 'remote_ratio', 'remote_bucket']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Baseline numerical features\n",
    "num_cols = [\n",
    "    'experience_level_ord','loc_freq','company_size_freq',\n",
    "    'posting_year','posting_month','posting_quarter','posting_dayofweek','days_since_posting'\n",
    "]\n",
    "\n",
    "# Remote bucket OHE columns\n",
    "remote_cols = [c for c in master.columns if c.startswith('remote_')]\n",
    "\n",
    "# Title OHE columns\n",
    "title_cols = [c for c in master.columns if c.startswith('title_')]\n",
    "\n",
    "# Skill OHE columns\n",
    "skill_cols = [c for c in master.columns if c.startswith('skill__')]\n",
    "\n",
    "feature_cols = num_cols + remote_cols + title_cols + skill_cols\n",
    "\n",
    "# Drop rows without target\n",
    "X = master[feature_cols].copy()\n",
    "y = master['log_salary_midpoint'].copy()\n",
    "\n",
    "mask = ~y.isna()\n",
    "X = X.loc[mask].fillna(0)\n",
    "y = y.loc[mask]\n",
    "\n",
    "print('X shape:', X.shape, '| y shape:', y.shape)\n",
    "print('Feature sample:', feature_cols[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c2c18e",
   "metadata": {},
   "source": [
    "## Train/Test split & save artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78de4d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\data\\processed\\X_train.csv \n",
      " C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\data\\processed\\X_test.csv \n",
      " C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\data\\processed\\y_train.csv \n",
      " C:\\Users\\tdmne\\OneDrive\\Desktop\\Projects 2\\datathon-2025\\data\\processed\\y_test.csv\n",
      "Artifacts:\n",
      " - \\mnt\\data\\feature_columns.csv\n",
      " - \\mnt\\data\\skill_vocab.json\n",
      " - \\mnt\\data\\preprocessing_config.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Stratify by experience bins when possible\n",
    "exp_bins = pd.cut(master.loc[mask, 'experience_level_ord'].fillna(-1), bins=[-1,0,1,2,3,10], labels=False, include_lowest=True)\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=exp_bins\n",
    "    )\n",
    "except Exception:\n",
    "    # Fallback if stratification fails\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "# Save to repo-structured path (if you run inside repo) and sandbox for download\n",
    "def save_dual(df: pd.DataFrame | pd.Series, name: str):\n",
    "    # Repo-structured path\n",
    "    out1 = DATA_PROCESSED / name\n",
    "    # Sandbox for immediate download\n",
    "    out2 = SANDBOX / name\n",
    "    if isinstance(df, pd.Series):\n",
    "        df.to_csv(out1, index=False, header=True)\n",
    "        df.to_csv(out2, index=False, header=True)\n",
    "    else:\n",
    "        df.to_csv(out1, index=False)\n",
    "        df.to_csv(out2, index=False)\n",
    "    return out1, out2\n",
    "\n",
    "p1, p2 = save_dual(X_train, 'X_train.csv')\n",
    "p3, p4 = save_dual(X_test,  'X_test.csv')\n",
    "p5, p6 = save_dual(y_train.to_frame('y'), 'y_train.csv')\n",
    "p7, p8 = save_dual(y_test.to_frame('y'),  'y_test.csv')\n",
    "\n",
    "print('Saved:')\n",
    "print(p1, '\\n', p3, '\\n', p5, '\\n', p7)\n",
    "\n",
    "# Save metadata artifacts\n",
    "feature_cols_path_1, feature_cols_path_2 = save_dual(pd.Series(feature_cols), 'feature_columns.csv')\n",
    "\n",
    "config = {\n",
    "    \"top_k_skills\": int(len(skill_cols)),\n",
    "    \"top_k_titles\": int(len(title_cols)),\n",
    "    \"remote_buckets\": remote_cols,\n",
    "    \"random_state\": 42,\n",
    "    \"target\": \"log_salary_midpoint\",\n",
    "    \"iqr_cap_k\": 1.5\n",
    "}\n",
    "(SANDBOX / 'preprocessing_config.json').write_text(json.dumps(config, indent=2))\n",
    "(SANDBOX / 'skill_vocab.json').write_text(json.dumps([c.replace('skill__','') for c in skill_cols], indent=2))\n",
    "\n",
    "print('Artifacts:')\n",
    "print(' -', SANDBOX / 'feature_columns.csv')\n",
    "print(' -', SANDBOX / 'skill_vocab.json')\n",
    "print(' -', SANDBOX / 'preprocessing_config.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5d7c6",
   "metadata": {},
   "source": [
    "## Quick quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57acd7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero features in X_train: 57 / 68\n",
      "All-zero columns dropped (inspect if unexpected): ['title_Data Analyst (Remote)', 'title_Data Analyst in office', 'title_Data Engineer (Remote)', 'title_Data Engineer in office', 'title_Data Scientist in office', 'title_Machine Learning Engineer (Remote)', 'title_Machine Learning Engineer in office', 'title_Statistician', 'title_Statistician (Remote)', 'title_Statistician in office', 'title_other']\n",
      "NaN values → train: 24000, test: 6000\n",
      "Inf values → train: 0, test: 0\n",
      "✅ Basic checks passed — all numeric and finite. Safe for modeling.\n"
     ]
    }
   ],
   "source": [
    "# === Final Fixed Quick Quality Checks ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Helper: find all-zero columns\n",
    "def nonzero_columns(df: pd.DataFrame):\n",
    "    nz = df.loc[:, (df != 0).any(axis=0)]\n",
    "    dropped = sorted(set(df.columns) - set(nz.columns))\n",
    "    return nz, dropped\n",
    "\n",
    "# 1️⃣ non-zero feature summary\n",
    "X_nz, dropped_cols = nonzero_columns(X_train)\n",
    "print(f\"Non-zero features in X_train: {X_nz.shape[1]} / {X_train.shape[1]}\")\n",
    "print(\"All-zero columns dropped (inspect if unexpected):\", dropped_cols)\n",
    "\n",
    "# 2️⃣ target leakage check\n",
    "assert 'log_salary_midpoint' not in X_train.columns, \"⚠️ Target leaked into features!\"\n",
    "\n",
    "# 3️⃣ ensure numeric + finite values safely\n",
    "# convert all to float to avoid dtype issues\n",
    "X_train_num = X_train.apply(pd.to_numeric, errors='coerce').astype(float)\n",
    "X_test_num  = X_test.apply(pd.to_numeric,  errors='coerce').astype(float)\n",
    "\n",
    "# check NaNs\n",
    "nan_train = X_train_num.isna().sum().sum()\n",
    "nan_test  = X_test_num.isna().sum().sum()\n",
    "\n",
    "# check infinite values (works now because dtype is float)\n",
    "inf_train = np.isinf(X_train_num.to_numpy(dtype=float)).sum()\n",
    "inf_test  = np.isinf(X_test_num.to_numpy(dtype=float)).sum()\n",
    "\n",
    "print(f\"NaN values → train: {nan_train}, test: {nan_test}\")\n",
    "print(f\"Inf values → train: {inf_train}, test: {inf_test}\")\n",
    "\n",
    "# 4️⃣ sanity assertions\n",
    "assert inf_train == 0 and inf_test == 0, \"⚠️ Found infinite values in data!\"\n",
    "\n",
    "print(\"✅ Basic checks passed — all numeric and finite. Safe for modeling.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a229cc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved:\n",
      " - ..\\data\\processed\\skill_vocab.json\n",
      " - ..\\data\\processed\\preprocessing_config.json\n"
     ]
    }
   ],
   "source": [
    "# === Save missing metadata artifacts locally ===\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PROCESSED = Path(\"../data/processed\")\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- skill_vocab.json ---\n",
    "skill_vocab = [c.replace('skill__', '') for c in X_train.columns if c.startswith('skill__')]\n",
    "(DATA_PROCESSED / \"skill_vocab.json\").write_text(json.dumps(skill_vocab, indent=2))\n",
    "\n",
    "# --- preprocessing_config.json ---\n",
    "config = {\n",
    "    \"top_k_skills\": len(skill_vocab),\n",
    "    \"feature_count\": X_train.shape[1],\n",
    "    \"random_state\": 42,\n",
    "    \"target\": \"log_salary_midpoint\",\n",
    "    \"iqr_cap_k\": 1.5\n",
    "}\n",
    "(DATA_PROCESSED / \"preprocessing_config.json\").write_text(json.dumps(config, indent=2))\n",
    "\n",
    "print(\"✅ Saved:\")\n",
    "print(\" -\", DATA_PROCESSED / \"skill_vocab.json\")\n",
    "print(\" -\", DATA_PROCESSED / \"preprocessing_config.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed237d8",
   "metadata": {},
   "source": [
    "\n",
    "## Next steps\n",
    "\n",
    "- **05_modeling_forecasting.ipynb** → Use `posting_year`, `posting_month`, skill bins over time to build per‑skill monthly series.\n",
    "- **06_modeling_salary_prediction.ipynb** → Load `X_train.csv`, `X_test.csv`, `y_train.csv`, `y_test.csv`; fit Linear/Ridge/XGBoost; log-target inverse transform with `expm1`.\n",
    "- **07_clustering_analysis.ipynb** → Use only skill OHE + key numerics; scale & run KMeans; profile clusters.\n",
    "- **08_recommendation_engine.ipynb** → Use skill embeddings or nearest-neighbor similarity for path suggestions. \n",
    "\n",
    "> Commit artifacts under `data/processed/` and the notebook under `notebooks/`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
