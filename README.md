# ğŸ“Š Skill Gap Analysis & Career Path Optimization

> A data-driven exploration of the global tech job market â€” identifying the most in-demand skills, analyzing salary trends, and revealing actionable insights to bridge the gap between industry demand and workforce readiness.


**ğŸ“… Academic Year:** 2025â€“26 (Semester VII Datathon)

---

## ğŸ‘¥ Team Members

* **Tirth Chankeshwara**
* **Tejas Deshmane**
* **Mahesh Bhimde**

---

## ğŸ¯ Problem Statement

The rapid evolution of technology has created a significant **skill gap** between what industries demand and what professionals currently possess. This project aims to:

* Forecast the **future demand** of tech skills (12â€“18 months ahead)
* Quantify **skill gaps** across roles, locations, and experience levels
* Analyze **salary variations** based on skill combinations
* Provide **data-driven career recommendations** and **learning paths**
* Visualize skill trends and insights through an **interactive dashboard**

---

## ğŸ“‚ Data Sources

We integrated three primary Kaggle datasets:

1. **Data Science Job Market (brsahan)** â€“ 10K+ listings; job titles, locations, salaries, skills.
2. **Job-Skill-Set (batuhanmutlu)** â€“ curated mapping of job roles to extracted skill sets.
3. **Global AI Job Market (bismasajjad)** â€“ 15K+ listings across 50+ countries with salary, experience, and company data.

**Integration Strategy:** Columns were harmonized (job titles, skills, currencies, experience) and merged into a unified `cleaned_master.csv` dataset.

---

## âš™ï¸ Methodology Overview

### **Phase 1 â€“ Data Collection & Cleaning**

* Gathered raw datasets from Kaggle sources.
* Standardized column names and data types.
* Handled missing values, duplicates, and outliers.
* Generated `data_quality_report.json` for validation metrics.

### **Phase 2 â€“ Pre-processing & Feature Engineering**

* Standardized skills using text normalization and taxonomy mapping.
* Engineered new features: `salary_midpoint`, `skill_count`, `posting_year`, etc.
* Created profiling snapshots (categorical & numerical).
* Exported cleaned dataset (`cleaned_master.csv`) for downstream analysis.

### **Phase 3 â€“ Exploratory Data Analysis (Ongoing)**

* Perform univariate, bivariate, and multivariate analyses.
* Identify correlations, skill trends, and salary distributions.
* Generate key insights for model design (forecasting, prediction, clustering).

### **Phase 4 â€“ Modeling & Forecasting**

* Apply ML algorithms: ARIMA/Prophet (skill forecasting), XGBoost (salary prediction), clustering for role patterns.

### **Phase 5 â€“ Visualization & Reporting**

* Develop Power BI dashboard showing trends, forecasts, and insights.
* Submit final report and presentation as per Datathon guidelines.

---

## ğŸ“ Repository Structure

```
datathon-2025/
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ dashboards/                      # Power BI / Tableau dashboards
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ README.md                    # Data dictionary and sources
â”‚   â”œâ”€â”€ external/                    # Supporting or reference datasets
â”‚   â”œâ”€â”€ processed/                   # Cleaned and merged data
â”‚   â”‚   â””â”€â”€ cleaned_master.csv
â”‚   â””â”€â”€ raw/                         # Original Kaggle datasets
â”‚       â”œâ”€â”€ dataset1_data_science_job.csv
â”‚       â”œâ”€â”€ dataset2_all_job_post.csv
â”‚       â”œâ”€â”€ dataset3_ai_job_dataset.csv
â”‚       â””â”€â”€ dataset3_ai_job_dataset1.csv
â”‚
â”œâ”€â”€ models/                          # Trained model files (.pkl, .sav)
â”‚
â”œâ”€â”€ notebooks/                       # Jupyter notebooks for each phase
â”‚   â”œâ”€â”€ 01_data_collection.ipynb
â”‚   â””â”€â”€ 02_data_cleaning.ipynb
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/                     # Visuals from EDA and reports
â”‚   â”œâ”€â”€ insights/                    # Textual insight summaries
â”‚   â””â”€â”€ tables/                      # Aggregated metrics / CSV summaries
â”‚
â”œâ”€â”€ reports/                         # Reports and data profiling results
â”‚   â”œâ”€â”€ data_quality_report.json
â”‚   â”œâ”€â”€ profiling_categorical_snapshot.csv
â”‚   â””â”€â”€ profiling_numeric_snapshot.csv
â”‚
â””â”€â”€ src/                             # Python scripts for preprocessing & modeling
```

---

## ğŸ§® Key Deliverables (Phase-Wise)

| Phase   | Deliverable                                        | Status         |
| ------- | -------------------------------------------------- | -------------- |
| Phase 1 | Dataset sourcing, schema validation                | âœ… Completed    |
| Phase 2 | Data cleaning, feature engineering, quality report | âœ… Completed    |
| Phase 3 | Exploratory Data Analysis & insight generation     | ğŸ”„ In Progress |
| Phase 4 | Modeling & evaluation                              | â³ Upcoming     |
| Phase 5 | Dashboard, final report & presentation             | â³ Upcoming     |

---

## ğŸ“Š Current Outputs

* `cleaned_master.csv` â†’ Unified master dataset (36 columns, ~36K rows)
* `profiling_categorical_snapshot.csv` / `profiling_numeric_snapshot.csv` â†’ Profiling statistics
* `data_quality_report.json` â†’ Completeness & validity summary

---

## ğŸš€ How to Run

```bash
git clone https://github.com/<username>/datathon-2025.git
cd datathon-2025
pip install -r requirements.txt
jupyter notebook notebooks/02_data_cleaning.ipynb
```

---

## ğŸ“ Academic Context

This project is developed as part of the **Data Analytics ISE Datathon (Sem VII)** under the Department of Electronics Engineering, WIT Solapur. It demonstrates application of the full **OSEMN pipeline** â€” *Obtain, Scrub, Explore, Model, iNterpret*.

---

## ğŸ“§ Contact

**Team Contact:** [work.tejasx@gmail.com](mailto:work.tejasx@gmail.com)

---

ğŸ“˜ *Walchand Institute of Technology, Solapur â€“ Data Analytics Datathon 2025â€“26*
